{"cells":[{"cell_type":"markdown","metadata":{"id":"0xt-OBYF0SoN"},"source":["# Set Environment"]},{"cell_type":"markdown","metadata":{"id":"qUSjaq2C0Xdl"},"source":["## import package"]},{"cell_type":"code","execution_count":177,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3109,"status":"ok","timestamp":1647093915039,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"TRBC-EUE487p","outputId":"6ace2275-7873-4743-da92-0f64a7003f38"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pythainlp in /usr/local/lib/python3.7/dist-packages (3.0.5)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (2.23.0)\n","Requirement already satisfied: tinydb>=3.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (4.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2021.10.8)\n","Requirement already satisfied: typing-extensions<5.0.0,>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from tinydb>=3.0->pythainlp) (3.10.0.2)\n"]}],"source":["!pip install pythainlp"]},{"cell_type":"code","execution_count":178,"metadata":{"id":"4TlOpoFD0Dhp","executionInfo":{"status":"ok","timestamp":1647093915039,"user_tz":-420,"elapsed":5,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f10a8acc-a3de-44a3-e0e6-5c9b2cdeac06"},"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import torchtext\n","import torch\n","import time\n","from torch import nn\n","import json, re, unicodedata, string, typing, time\n","import torch.nn.functional as F\n","import spacy\n","from collections import Counter\n","import pickle\n","from pythainlp.tokenize import word_tokenize\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"9-Ov1HJ10cSr"},"source":["## mount google drive"]},{"cell_type":"code","execution_count":179,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2919,"status":"ok","timestamp":1647093919635,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"O-p2gMyc0VsH","outputId":"ba922787-81f5-444b-c79d-2c20fd75082e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#mount my google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":180,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1647093919636,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"HJvZp-V60tov","outputId":"43a11918-3f29-4eed-90ae-42795b96f24a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/BADS9000_IS/Colab-DrQA\n"]}],"source":["%cd /content/drive/MyDrive/Colab Notebooks/BADS9000_IS/Colab-DrQA"]},{"cell_type":"markdown","metadata":{"id":"v15bqdFi0x60"},"source":["# Load Data"]},{"cell_type":"code","execution_count":181,"metadata":{"id":"fQr6hmZ_1K4I","executionInfo":{"status":"ok","timestamp":1647093923477,"user_tz":-420,"elapsed":1,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["def load_pickle(path_file):\n","    with open(path_file, 'rb') as file:\n","        load_obj = pickle.load(file)\n","        print(f\"load object from {path_file} success,that is {type(load_obj)}\")\n","        return load_obj"]},{"cell_type":"code","execution_count":183,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4559,"status":"ok","timestamp":1647094004297,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"rIRTAEoL00jS","outputId":"506e19c5-2d23-4546-dc8e-3d8f48d3de8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["load object from ./drqa/1-tokenizers/result/df_ThaiQACorpus_prepairing.pkl success,that is <class 'pandas.core.frame.DataFrame'>\n","load object from ./drqa/1-tokenizers/result/dict_word2idx.pkl success,that is <class 'dict'>\n","load object from ./drqa/1-tokenizers/result/dict_idx2word.pkl success,that is <class 'dict'>\n","load object from ./drqa/1-tokenizers/result/list_word_vocab.pkl success,that is <class 'list'>\n","load object from ./drqa/1-tokenizers/result/dict_embed_ltw2v.pkl success,that is <class 'dict'>\n","CPU times: user 2.81 s, sys: 1.52 s, total: 4.33 s\n","Wall time: 4.37 s\n"]}],"source":["%%time\n","file = \"ThaiQACorpus\"\n","df_qa = load_pickle(f\"./drqa/1-tokenizers/result/df_{file}_prepairing.pkl\")\n","word2idx = load_pickle(\"./drqa/1-tokenizers/result/dict_word2idx.pkl\")\n","idx2word  = load_pickle(\"./drqa/1-tokenizers/result/dict_idx2word.pkl\")\n","word_vocab = load_pickle(\"./drqa/1-tokenizers/result/list_word_vocab.pkl\")\n","glove_dict =  load_pickle(\"./drqa/1-tokenizers/result/dict_embed_ltw2v.pkl\")\n","weights_matrix = np.load('./drqa/1-tokenizers/result/dfqa2v_ltw2v.npy')"]},{"cell_type":"code","execution_count":184,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":410,"status":"ok","timestamp":1647094012212,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"tO_2Q4EGLHiS","outputId":"ee1edb3b-d16f-4864-82d4-5367e01a8509"},"outputs":[{"output_type":"stream","name":"stdout","text":["number of element in dict 731,185\n","shape of element in dict (300,)\n","type of element in dict <class 'numpy.ndarray'>\n","number of word not found in dict : 24,627\n"]}],"source":["print(f\"number of element in dict {len(glove_dict):0,.0f}\")\n","print(f\"shape of element in dict {glove_dict['that'].shape}\")\n","print(f\"type of element in dict {type(glove_dict['that'])}\")\n","print(f\"number of word not found in dict : {np.sum(weights_matrix.sum(axis=1)==0):0,.0f}\")"]},{"cell_type":"code","execution_count":185,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1647094013895,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"NFVFfAjG1Wjl","outputId":"d5b9ffc9-3a97-4346-9bef-9e96a8965834"},"outputs":[{"output_type":"stream","name":"stdout","text":["type(train_df):<class 'pandas.core.frame.DataFrame'>, train_df.shape:(9306, 8), #columns:8\n","type(valid_df):<class 'pandas.core.frame.DataFrame'>, valid_df.shape:(1034, 8), #columns:8\n"]}],"source":["from sklearn.model_selection import train_test_split\n","df_qa = df_qa[df_qa.context_ids.apply(lambda x:len(x))<850][['id', 'context', 'question', 'label', 'answer', 'context_ids', 'question_ids', 'label_idx']].reset_index(drop=True)\n","train_df, valid_df = train_test_split(df_qa, test_size=0.1 , random_state=12345)\n","train_df = train_df.reset_index(drop=True)\n","valid_df = valid_df.reset_index(drop=True)\n","print(f\"type(train_df):{type(train_df)}, train_df.shape:{train_df.shape}, #columns:{len(train_df.columns)}\")\n","print(f\"type(valid_df):{type(valid_df)}, valid_df.shape:{valid_df.shape}, #columns:{len(valid_df.columns)}\")"]},{"cell_type":"markdown","metadata":{"id":"XUhnn56g0wk9"},"source":["# Create Torch Batch"]},{"cell_type":"code","execution_count":186,"metadata":{"id":"WQDzsUm_2UqS","executionInfo":{"status":"ok","timestamp":1647094028504,"user_tz":-420,"elapsed":433,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["class SquadDataset:\n","    '''\n","    -Divides the dataframe in batches.\n","    -Pads the contexts and questions dynamically for each batch by padding \n","     the examples to the maximum-length sequence in that batch.\n","    -Calculates masks for context and question.\n","    -Calculates spans for contexts.\n","    '''\n","    \n","    def __init__(self, data, batch_size):\n","        \n","        self.batch_size = batch_size\n","        data = [data[i:i+self.batch_size] for i in range(0, len(data), self.batch_size)]\n","        self.data = data\n","    \n","    def get_span(self, text):\n","        \n","        lst_token = word_tokenize(text ,engine='newmm')\n","        span  = [(len(\"\".join(lst_token[0:i])), len(\"\".join(lst_token[0:i+1]))) \n","                         for i,w in enumerate(lst_token)]\n","        return span\n","\n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __iter__(self):\n","        '''\n","        Creates batches of data and yields them.\n","        \n","        Each yield comprises of:\n","        :padded_context: padded tensor of contexts for each batch \n","        :padded_question: padded tensor of questions for each batch \n","        :context_mask & question_mask: zero-mask for question and context\n","        :label: start and end index wrt context_ids\n","        :context_text,answer_text: used while validation to calculate metrics\n","        :context_spans: spans of context text\n","        :ids: question_ids used in evaluation\n","        '''\n","        \n","        for batch in self.data:\n","                            \n","            spans = []\n","            context_text = []\n","            answer_text = []\n","            \n","            max_context_len = max([len(ctx) for ctx in batch.context_ids])\n","            padded_context = torch.LongTensor(len(batch), max_context_len).fill_(1)\n","            \n","            for ctx in batch.context:\n","                context_text.append(ctx)\n","                spans.append(self.get_span(ctx))\n","            \n","            for ans in batch.answer:\n","                answer_text.append(ans)\n","                \n","            for i, ctx in enumerate(batch.context_ids):\n","                padded_context[i, :len(ctx)] = torch.LongTensor(ctx)\n","            \n","            max_question_len = max([len(ques) for ques in batch.question_ids])\n","            padded_question = torch.LongTensor(len(batch), max_question_len).fill_(1)\n","            \n","            for i, ques in enumerate(batch.question_ids):\n","                padded_question[i,: len(ques)] = torch.LongTensor(ques)\n","                \n","            \n","            label = torch.LongTensor(list(batch.label_idx))\n","            context_mask = torch.eq(padded_context, 1)\n","            question_mask = torch.eq(padded_question, 1)\n","            \n","            ids = list(batch.id)  \n","            \n","            yield (padded_context, padded_question, context_mask, \n","                   question_mask, label, context_text, answer_text, ids)"]},{"cell_type":"code","source":["#if maximum number of token is too big, it use more GPU\n","# context_ids , question_ids are to big, it have size 200K when in english have size 810\n","print(f\"maximum number of token in question_ids : {train_df.context_ids.apply(lambda x:len(x)).max()}\")\n","print(f\"maximum number of token in question_ids : {train_df.question_ids.apply(lambda x:len(x)).max()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16HD790QdieB","executionInfo":{"status":"ok","timestamp":1647094028925,"user_tz":-420,"elapsed":6,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"08d7b3dd-594b-4d05-9a65-f0e9ffc1b079"},"execution_count":187,"outputs":[{"output_type":"stream","name":"stdout","text":["maximum number of token in question_ids : 849\n","maximum number of token in question_ids : 57\n"]}]},{"cell_type":"code","execution_count":188,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1647094028928,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"SKPAebdo2Z46","outputId":"d76c7d5e-894b-49bf-8508-12f87fd5069a"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n","Wall time: 5.25 µs\n","type(train_dataset):<class '__main__.SquadDataset'>\n","type(valid_dataset):<class '__main__.SquadDataset'>\n"]}],"source":["%time\n","train_dataset = SquadDataset(train_df, 32)\n","valid_dataset = SquadDataset(valid_df, 32)\n","print(f\"type(train_dataset):{type(train_dataset)}\")\n","print(f\"type(valid_dataset):{type(valid_dataset)}\")"]},{"cell_type":"code","source":["train_df.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"9o5NZY1jmxYd","executionInfo":{"status":"ok","timestamp":1647094028929,"user_tz":-420,"elapsed":9,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"5e794263-263d-4648-c3c3-bfccf76fbc1a"},"execution_count":189,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     id                                            context  \\\n","0  7983  บ้านซอยสวนพลู บ้านซอยสวนพลู เป็นชื่อที่ใช้เรีย...   \n","\n","                                            question       label     answer  \\\n","0  ม.ร.ว.คึกฤทธิ์ ปราโมช เข้าอยู่อาศัยในบ้านซอยสว...  [434, 443]  พ.ศ. 2503   \n","\n","                                         context_ids  \\\n","0  [139, 1612, 556, 5721, 2, 139, 1612, 556, 5721...   \n","\n","                                        question_ids   label_idx  \n","0  [4945, 6018, 2, 4356, 2, 112, 6809, 3, 139, 16...  [128, 130]  "],"text/html":["\n","  <div id=\"df-a5b65cf3-3680-489b-a356-6a2c3875c648\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>label</th>\n","      <th>answer</th>\n","      <th>context_ids</th>\n","      <th>question_ids</th>\n","      <th>label_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7983</td>\n","      <td>บ้านซอยสวนพลู บ้านซอยสวนพลู เป็นชื่อที่ใช้เรีย...</td>\n","      <td>ม.ร.ว.คึกฤทธิ์ ปราโมช เข้าอยู่อาศัยในบ้านซอยสว...</td>\n","      <td>[434, 443]</td>\n","      <td>พ.ศ. 2503</td>\n","      <td>[139, 1612, 556, 5721, 2, 139, 1612, 556, 5721...</td>\n","      <td>[4945, 6018, 2, 4356, 2, 112, 6809, 3, 139, 16...</td>\n","      <td>[128, 130]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5b65cf3-3680-489b-a356-6a2c3875c648')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a5b65cf3-3680-489b-a356-6a2c3875c648 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a5b65cf3-3680-489b-a356-6a2c3875c648');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":189}]},{"cell_type":"code","execution_count":190,"metadata":{"executionInfo":{"elapsed":446,"status":"ok","timestamp":1647094029367,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"Rd3R23sH2dv3"},"outputs":[],"source":["padded_context, padded_question, context_mask, question_mask, label, context_text, answer_text, ids = next(iter(train_dataset))"]},{"cell_type":"code","source":["padded_context[0][~context_mask[0]] "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GaUGZ5Crl85m","executionInfo":{"status":"ok","timestamp":1647094029367,"user_tz":-420,"elapsed":10,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"57626eff-3b6d-4628-aa60-e24fa1a67578"},"execution_count":191,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([  139,  1612,   556,  5721,     2,   139,  1612,   556,  5721,     2,\n","            7,    65,     5,    35,  7300,  3741,     8,  4945,  6018,     2,\n","         4356,     2,   187,     3,  2670,     2,   598,     2,  1612,    28,\n","         6245,     2,    23,     7,  1612,  1045,     8,  1612,   556,  5721,\n","            2,    10,  1612,  6771,     2,    46,    11,     2,   210,  6771,\n","          280,     2,   147,  6771,     2,   139,  1612,   556,  5721,   287,\n","          132,   120,     2,    83,     2,   837,     2,     5,  4945,  6018,\n","         1071,   125,   145,     2,    15,     2,  4741,     2,   409,  2061,\n","           36,   679,   168,     2,    83,     2,   198,     2,  2061,   161,\n","          198,   277,  1071,   160,  1685,  1474,  7773,     2,    27,     2,\n","           15,     2,  3937,     2,     6,  2061,    36,   239,   277,    90,\n","            2,    43,     2,   198,  1071,   160,     2,    68, 14678,     2,\n","         2975,     2,    13,   255,  2061,   915,    27,     2,    15,     2,\n","         3281,     2,    16,    35,  1821,  4531,  2061,    19,    68, 14678,\n","            2,  2061,   161,   198,   277,    40, 32090,     7,  7410,  4457,\n","            2,    20,    71,    20,    27,   494,  2061,    30,    31,     5,\n","         1612,   556,  5721,     2,  2570,     8,   298,    37,    54,  7728,\n","          696,  2146,    41,     2,  3969,  1172,  6018,     2,   176,   401,\n","          125,     3,   382,     8,   298,     2,   310,  7216,  2061,    20,\n","          176, 71405,     2,    10,    19,  4257,   958,     8,  1183,     3,\n","            2,    15,     2,  2130,    11,     2,  6051,     2,   139,   198,\n","           40,     7,     8, 14918,     2,    28,  6245,  1250,  1517,     2,\n","         2352,     8,     2,  4945,   308,   560,   281,     2,  6245,  1250,\n","         1517,     2,  3241,     8,  4945,  6018,     2,     6,  4945,  7393,\n","            2,  4356,     2,    35,     7,   398,     8,  1231,     3,  5760,\n","         4356,     2,   647,     3,   128,  1987,    22,    55,   898,    16,\n","          233,     2,     6,    55,    35,     7, 11457,     8,   283,   151,\n","            2,  4796,  4945,   308,   560,   281,  2912,    65,     7,     8,\n","          735,   740,   199,     2,  1562,  1111,    30,    31,     3,    98,\n","         2972,     8,  4945,  6018,     2,     3,    51,     2,   536,     2,\n","          414,     2,    15,     2,  2130,     2,   166,     5,     2,  4945,\n","         6018,     2,  4356,     2,     7,   521,     2,   139,   198,    40,\n","           12,    55,  1183,     2,   134,    16,     2, 24589,  4261,     2,\n","         3160,  3596,     2,  7869,   958, 10649,     2,    23,  4945,  6018,\n","           25,    31,   139,     2,  1403,   183,   129,  1183,    25,  3724,\n","         4945,  6018,     2,   521,     2,  1978,    61,   309,    26,  6860,\n","         2022,    55,  3252,     5,  1614,     2,    19,  1403,  4179,  7255,\n","            2,    23,  1122,  2576,    24, 14129,    12,     2, 15357,    78,\n","         7497,   193,  1183,  1902,     2,  4945,  6018,     2,  4356,     2,\n","          112,  6809,     3,   139,    40,    27,     2,    15,     2,  3281,\n","            2,     6,  1835,    26,  3604,     2,   911,   152,  7708,    18,\n","            2,   144,  5238,    27,     2,    15,     2,  1059,     2,    77,\n","         3370,    12,  3353,     7,  2673,     2,   321,   139,   431,   182,\n","            2,     6,   224,     7,     2,  1127,   139,     2,  4945,  6018,\n","            2,  4356,     2,    31,     3,    13,  1001,     8,     2,  1497,\n","         6018,     2,  1831,     2,     3, 17097,     2,  3528,     2,     3,\n","          107,   420,     2,    15,     2,   600,     2,     9,  1067,    20,\n","          139,  1612,   556,  5721,    22,  1145,   800,   123,     2,  4347,\n","         1031,    69,   455,  8243,    12,    16,  4440,  1497,     6,  3474,\n","           24,   224,  1030,   751,     2])"]},"metadata":{},"execution_count":191}]},{"cell_type":"code","source":["padded_question[0][~question_mask[0]]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b6Mj6Me3l88l","executionInfo":{"status":"ok","timestamp":1647094029368,"user_tz":-420,"elapsed":9,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"17134300-031d-4b58-d549-a94ea93edb8a"},"execution_count":192,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([4945, 6018,    2, 4356,    2,  112, 6809,    3,  139, 1612,  556, 5721,\n","          27,   18,  104])"]},"metadata":{},"execution_count":192}]},{"cell_type":"code","source":[""],"metadata":{"id":"9ar9NSral9Ic","executionInfo":{"status":"ok","timestamp":1647094029370,"user_tz":-420,"elapsed":7,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"execution_count":195,"outputs":[]},{"cell_type":"markdown","source":["# Create Layer function"],"metadata":{"id":"ycQcxXYIBEgH"}},{"cell_type":"code","execution_count":201,"metadata":{"id":"3A2FYP2U2hDI","executionInfo":{"status":"ok","timestamp":1647094036892,"user_tz":-420,"elapsed":1,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["class AlignQuestionEmbedding(nn.Module):\n","    \n","    def __init__(self, input_dim):        \n","        \n","        super().__init__()\n","        \n","        self.linear = nn.Linear(input_dim, input_dim)\n","        \n","        self.relu = nn.ReLU()\n","        \n","    def forward(self, context, question, question_mask):\n","        \n","        # context = [bs, ctx_len, emb_dim]\n","        # question = [bs, qtn_len, emb_dim]\n","        # question_mask = [bs, qtn_len]\n","    \n","        ctx_ = self.linear(context)\n","        ctx_ = self.relu(ctx_)\n","        # ctx_ = [bs, ctx_len, emb_dim]\n","        \n","        qtn_ = self.linear(question)\n","        qtn_ = self.relu(qtn_)\n","        # qtn_ = [bs, qtn_len, emb_dim]\n","        \n","        qtn_transpose = qtn_.permute(0,2,1)\n","        # qtn_transpose = [bs, emb_dim, qtn_len]\n","        \n","        align_scores = torch.bmm(ctx_, qtn_transpose)\n","        # align_scores = [bs, ctx_len, qtn_len]\n","        \n","        qtn_mask = question_mask.unsqueeze(1).expand(align_scores.size())\n","        # qtn_mask = [bs, 1, qtn_len] => [bs, ctx_len, qtn_len]\n","        \n","        # Fills elements of self tensor(align_scores) with value(-float(inf)) where mask is True. \n","        # The shape of mask must be broadcastable with the shape of the underlying tensor.\n","        align_scores = align_scores.masked_fill(qtn_mask == 1, -float('inf'))\n","        # align_scores = [bs, ctx_len, qtn_len]\n","        \n","        align_scores_flat = align_scores.view(-1, question.size(1))\n","        # align_scores = [bs*ctx_len, qtn_len]\n","        \n","        alpha = F.softmax(align_scores_flat, dim=1)\n","        alpha = alpha.view(-1, context.shape[1], question.shape[1])\n","        # alpha = [bs, ctx_len, qtn_len]\n","        \n","        align_embedding = torch.bmm(alpha, question)\n","        # align = [bs, ctx_len, emb_dim]\n","        \n","        return align_embedding"]},{"cell_type":"code","execution_count":202,"metadata":{"id":"hHTKEop52pMB","executionInfo":{"status":"ok","timestamp":1647094037464,"user_tz":-420,"elapsed":3,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["class StackedBiLSTM(nn.Module):\n","    \n","    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n","        \n","        super().__init__()\n","        \n","        self.dropout = dropout\n","        \n","        self.num_layers = num_layers\n","        \n","        self.lstms = nn.ModuleList()\n","        \n","        for i in range(self.num_layers):\n","            \n","            input_dim = input_dim if i == 0 else hidden_dim * 2\n","            \n","            self.lstms.append(nn.LSTM(input_dim, hidden_dim,\n","                                      batch_first=True, bidirectional=True))\n","           \n","    \n","    def forward(self, x):\n","        # x = [bs, seq_len, feature_dim]\n","\n","        outputs = [x]\n","        for i in range(self.num_layers):\n","\n","            lstm_input = outputs[-1]\n","            lstm_out = F.dropout(lstm_input, p=self.dropout)\n","            lstm_out, (hidden, cell) = self.lstms[i](lstm_input)\n","           \n","            outputs.append(lstm_out)\n","\n","    \n","        output = torch.cat(outputs[1:], dim=2)\n","        # [bs, seq_len, num_layers*num_dir*hidden_dim]\n","        \n","        output = F.dropout(output, p=self.dropout)\n","      \n","        return output"]},{"cell_type":"code","execution_count":203,"metadata":{"id":"m9hl1zqi2uCW","executionInfo":{"status":"ok","timestamp":1647094037465,"user_tz":-420,"elapsed":3,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["class LinearAttentionLayer(nn.Module):\n","    \n","    def __init__(self, input_dim):\n","        \n","        super().__init__()\n","        \n","        self.linear = nn.Linear(input_dim, 1)\n","        \n","    def forward(self, question, question_mask):\n","        \n","        # question = [bs, qtn_len, input_dim] = [bs, qtn_len, bi_lstm_hid_dim]\n","        # question_mask = [bs,  qtn_len]\n","        \n","        qtn = question.view(-1, question.shape[-1])\n","        # qtn = [bs*qtn_len, hid_dim]\n","        \n","        attn_scores = self.linear(qtn)\n","        # attn_scores = [bs*qtn_len, 1]\n","        \n","        attn_scores = attn_scores.view(question.shape[0], question.shape[1])\n","        # attn_scores = [bs, qtn_len]\n","        \n","        attn_scores = attn_scores.masked_fill(question_mask == 1, -float('inf'))\n","        \n","        alpha = F.softmax(attn_scores, dim=1)\n","        # alpha = [bs, qtn_len]\n","        \n","        return alpha      "]},{"cell_type":"code","execution_count":204,"metadata":{"id":"xMAiQuaQ2wlW","executionInfo":{"status":"ok","timestamp":1647094037465,"user_tz":-420,"elapsed":3,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["def weighted_average(x, weights):\n","    # x = [bs, len, dim]\n","    # weights = [bs, len]\n","    \n","    weights = weights.unsqueeze(1)\n","    # weights = [bs, 1, len]\n","    \n","    w = weights.bmm(x).squeeze(1)\n","    # w = [bs, 1, dim] => [bs, dim]\n","    \n","    return w"]},{"cell_type":"code","execution_count":205,"metadata":{"id":"K-cDhxpt20w9","executionInfo":{"status":"ok","timestamp":1647094037465,"user_tz":-420,"elapsed":3,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["class BilinearAttentionLayer(nn.Module):\n","    \n","    def __init__(self, context_dim, question_dim):\n","        \n","        super().__init__()\n","        \n","        self.linear = nn.Linear(question_dim, context_dim)\n","        \n","    def forward(self, context, question, context_mask):\n","        \n","        # context = [bs, ctx_len, ctx_hid_dim] = [bs, ctx_len, hid_dim*6] = [bs, ctx_len, 768]\n","        # question = [bs, qtn_hid_dim] = [bs, qtn_len, 768]\n","        # context_mask = [bs, ctx_len]\n","        \n","        qtn_proj = self.linear(question)\n","        # qtn_proj = [bs, ctx_hid_dim]\n","        \n","        qtn_proj = qtn_proj.unsqueeze(2)\n","        # qtn_proj = [bs, ctx_hid_dim, 1]\n","        \n","        scores = context.bmm(qtn_proj)\n","        # scores = [bs, ctx_len, 1]\n","        \n","        scores = scores.squeeze(2)\n","        # scores = [bs, ctx_len]\n","        \n","        scores = scores.masked_fill(context_mask == 1, -float('inf'))\n","        \n","        #alpha = F.log_softmax(scores, dim=1)\n","        # alpha = [bs, ctx_len]\n","        \n","        return scores"]},{"cell_type":"markdown","source":["# Create Model"],"metadata":{"id":"iCE-4y01BTgb"}},{"cell_type":"markdown","source":["## Define Sturcture"],"metadata":{"id":"MCE3wZTMBXwm"}},{"cell_type":"code","execution_count":206,"metadata":{"id":"JGIVpX8f26BS","executionInfo":{"status":"ok","timestamp":1647094042856,"user_tz":-420,"elapsed":430,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["class DocumentReader(nn.Module):\n","    \n","    def __init__(self, hidden_dim, embedding_dim, num_layers, num_directions, dropout, device):\n","        \n","        super().__init__()\n","        \n","        self.device = device\n","        \n","        #self.embedding = self.get_glove_embedding()\n","        \n","        self.context_bilstm = StackedBiLSTM(embedding_dim * 2, hidden_dim, num_layers, dropout)\n","        \n","        self.question_bilstm = StackedBiLSTM(embedding_dim, hidden_dim, num_layers, dropout)\n","        \n","        self.glove_embedding = self.get_glove_embedding()\n","        \n","        def tune_embedding(grad, words=61036):\n","            grad[words:] = 0\n","            return grad\n","        \n","        #self.glove_embedding.weight.register_hook(tune_embedding)\n","        \n","        self.align_embedding = AlignQuestionEmbedding(embedding_dim)\n","        \n","        self.linear_attn_question = LinearAttentionLayer(hidden_dim*num_layers*num_directions) \n","        \n","        self.bilinear_attn_start = BilinearAttentionLayer(hidden_dim*num_layers*num_directions, \n","                                                          hidden_dim*num_layers*num_directions)\n","        \n","        self.bilinear_attn_end = BilinearAttentionLayer(hidden_dim*num_layers*num_directions,\n","                                                        hidden_dim*num_layers*num_directions)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","   \n","        \n","    def get_glove_embedding(self):\n","        \n","        weights_matrix = np.load('./drqa/1-tokenizers/result/dfqa2v_ltw2v.npy')\n","        num_embeddings, embedding_dim = weights_matrix.shape\n","        embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights_matrix).to(self.device),freeze=False ,padding_idx=0)\n","\n","        return embedding\n","    \n","    \n","    def forward(self, context, question, context_mask, question_mask):\n","       \n","        # context = [bs, len_c]\n","        # question = [bs, len_q]\n","        # context_mask = [bs, len_c]\n","        # question_mask = [bs, len_q]\n","        \n","        \n","        ctx_embed = self.glove_embedding(context)\n","        # ctx_embed = [bs, len_c, emb_dim]\n","        \n","        ques_embed = self.glove_embedding(question)\n","        # ques_embed = [bs, len_q, emb_dim]\n","        \n","\n","        ctx_embed = self.dropout(ctx_embed)\n","     \n","        ques_embed = self.dropout(ques_embed)\n","             \n","        align_embed = self.align_embedding(ctx_embed, ques_embed, question_mask)\n","        # align_embed = [bs, len_c, emb_dim]  \n","        \n","        ctx_bilstm_input = torch.cat([ctx_embed, align_embed], dim=2)\n","        # ctx_bilstm_input = [bs, len_c, emb_dim*2]\n","                \n","        ctx_outputs = self.context_bilstm(ctx_bilstm_input)\n","        # ctx_outputs = [bs, len_c, hid_dim*layers*dir] = [bs, len_c, hid_dim*6]\n","       \n","        qtn_outputs = self.question_bilstm(ques_embed)\n","        # qtn_outputs = [bs, len_q, hid_dim*6]\n","    \n","        qtn_weights = self.linear_attn_question(qtn_outputs, question_mask)\n","        # qtn_weights = [bs, len_q]\n","            \n","        qtn_weighted = weighted_average(qtn_outputs, qtn_weights)\n","        # qtn_weighted = [bs, hid_dim*6]\n","        \n","        start_scores = self.bilinear_attn_start(ctx_outputs, qtn_weighted, context_mask)\n","        # start_scores = [bs, len_c]\n","         \n","        end_scores = self.bilinear_attn_end(ctx_outputs, qtn_weighted, context_mask)\n","        # end_scores = [bs, len_c]\n","        \n","      \n","        return start_scores, end_scores"]},{"cell_type":"markdown","metadata":{"id":"z_Ui7-6r3Lzy"},"source":["## Model Setting"]},{"cell_type":"code","execution_count":207,"metadata":{"id":"xWQTTv0g3OSa","executionInfo":{"status":"ok","timestamp":1647094042857,"user_tz":-420,"elapsed":3,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["device = torch.device('cuda')\n","EMB_DIM = 300\n","HIDDEN_DIM = 128\n","NUM_LAYERS = 1\n","NUM_DIRECTIONS = 2\n","DROPOUT = 0.3\n","device = torch.device('cuda')\n","\n","model = DocumentReader(HIDDEN_DIM, EMB_DIM,  NUM_LAYERS,  NUM_DIRECTIONS,  DROPOUT,  device).to(device)"]},{"cell_type":"code","execution_count":208,"metadata":{"id":"MVPCFwjH3Vk-","executionInfo":{"status":"ok","timestamp":1647094043460,"user_tz":-420,"elapsed":606,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["optimizer = torch.optim.Adamax(model.parameters())"]},{"cell_type":"code","execution_count":209,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1647094043461,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"iSCuqHql3XM6","outputId":"e998b07d-7056-4f96-8d09-c49b9bae3362"},"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 34,977,281 trainable parameters\n"]}],"source":["def count_parameters(model):\n","    '''Returns the number of trainable parameters in the model.'''\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"]},{"cell_type":"markdown","metadata":{"id":"EaD2ccj13Reb"},"source":["# Create Model Training Flow"]},{"cell_type":"code","execution_count":210,"metadata":{"id":"huVw5nOs3XTX","executionInfo":{"status":"ok","timestamp":1647094045969,"user_tz":-420,"elapsed":2,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["def train(model, train_dataset):\n","    '''\n","    Trains the model.\n","    '''\n","    \n","    print(\"Starting training ........\")\n","    \n","    train_loss = 0.\n","    batch_count = 0\n","    \n","    # put the model in training mode\n","    model.train()\n","    \n","    # iterate through training data\n","    for batch in train_dataset:\n","\n","        if batch_count % 50 == 0:\n","            print(f\"Starting batch: {batch_count}\")\n","        batch_count += 1\n","\n","        context, question, context_mask, question_mask, label, ctx, ans, ids = batch\n","        \n","        # place the tensors on GPU\n","        context, context_mask, question, question_mask, label = context.to(device), context_mask.to(device),\\\n","                                    question.to(device), question_mask.to(device), label.to(device)\n","        \n","        # forward pass, get the predictions\n","        preds = model(context, question, context_mask, question_mask)\n","\n","        start_pred, end_pred = preds\n","        \n","        # separate labels for start and end position\n","        start_label, end_label = label[:,0], label[:,1]\n","        \n","        # calculate loss\n","        loss = F.cross_entropy(start_pred, start_label) + F.cross_entropy(end_pred, end_label)\n","        \n","        # backward pass, calculates the gradients\n","        loss.backward()\n","        \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n","        \n","        # update the gradients\n","        optimizer.step()\n","        \n","        # zero the gradients to prevent them from accumulating\n","        optimizer.zero_grad()\n","\n","        train_loss += loss.item()\n","\n","    return train_loss/len(train_dataset)"]},{"cell_type":"code","execution_count":211,"metadata":{"id":"1i090lL03XWF","executionInfo":{"status":"ok","timestamp":1647094046387,"user_tz":-420,"elapsed":6,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["def valid(model, valid_dataset):\n","    '''\n","    Performs validation.\n","    '''\n","    \n","    print(\"Starting validation .........\")\n","   \n","    valid_loss = 0.\n","\n","    batch_count = 0\n","    \n","    f1, em = 0., 0.\n","    \n","    # puts the model in eval mode. Turns off dropout\n","    model.eval()\n","    \n","    predictions = {}\n","    \n","    for batch in valid_dataset:\n","\n","        if batch_count % 500 == 0:\n","            print(f\"Starting batch {batch_count}\")\n","        batch_count += 1\n","\n","        context, question, context_mask, question_mask, label, context_text, answers, ids = batch\n","\n","        context, context_mask, question, question_mask, label = context.to(device), context_mask.to(device),\\\n","                                    question.to(device), question_mask.to(device), label.to(device)\n","\n","        with torch.no_grad():\n","\n","            preds = model(context, question, context_mask, question_mask)\n","\n","            p1, p2 = preds\n","\n","            y1, y2 = label[:,0], label[:,1]\n","\n","            loss = F.cross_entropy(p1, y1) + F.cross_entropy(p2, y2)\n","\n","            valid_loss += loss.item()\n","\n","            \n","            # get the start and end index positions from the model preds\n","            \n","            batch_size, c_len = p1.size()\n","            ls = nn.LogSoftmax(dim=1)\n","            mask = (torch.ones(c_len, c_len) * float('-inf')).to(device).tril(-1).unsqueeze(0).expand(batch_size, -1, -1)\n","            \n","            score = (ls(p1).unsqueeze(2) + ls(p2).unsqueeze(1)) + mask\n","            score, s_idx = score.max(dim=1)\n","            score, e_idx = score.max(dim=1)\n","            s_idx = torch.gather(s_idx, 1, e_idx.view(-1, 1)).squeeze()\n","            \n","            # stack predictions\n","            for i in range(batch_size):\n","                id = ids[i]\n","                pred = context[i][s_idx[i]:e_idx[i]+1]\n","                pred = ' '.join([idx2word[idx.item()] for idx in pred])\n","                predictions[id] = pred\n","            \n","            \n","            \n","    em, f1 = evaluate(predictions)            \n","    return valid_loss/len(valid_dataset), em, f1"]},{"cell_type":"code","execution_count":212,"metadata":{"id":"705PMhOB3XZH","executionInfo":{"status":"ok","timestamp":1647094046387,"user_tz":-420,"elapsed":5,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["def evaluate(predictions):\n","    '''\n","    Gets a dictionary of predictions with question_id as key\n","    and prediction as value. The validation dataset has multiple \n","    answers for a single question. Hence we compare our prediction\n","    with all the answers and choose the one that gives us\n","    the maximum metric (em or f1). \n","    This method first parses the JSON file, gets all the answers\n","    for a given id and then passes the list of answers and the \n","    predictions to calculate em, f1.\n","    \n","    \n","    :param dict predictions\n","    Returns\n","    : exact_match: 1 if the prediction and ground truth  match exactly, 0 otherwise.\n","    : f1_score: \n","    '''\n","    f1 = exact_match = total = 0\n","    for ctx_id in  valid_df.id[valid_df.id.isin(predictions.keys())].unique():\n","      ground_truths = valid_df[valid_df.id == ctx_id][\"answer\"].to_list()\n","      prediction = predictions[ctx_id]\n","      exact_match += metric_max_over_ground_truths( exact_match_score, prediction, ground_truths)\n","      f1 += metric_max_over_ground_truths(f1_score, prediction, ground_truths)\n","      total += 1\n","    \n","    exact_match = 100.0 * exact_match / total\n","    f1 = 100.0 * f1 / total\n","    \n","    return exact_match, f1"]},{"cell_type":"code","source":["def normalize_answer(s):\n","    '''\n","    Performs a series of cleaning steps on the ground truth and \n","    predicted answer.\n","    '''\n","    def remove_articles(text):\n","        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))"],"metadata":{"id":"p263RUQLBxAQ","executionInfo":{"status":"ok","timestamp":1647094047139,"user_tz":-420,"elapsed":756,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"execution_count":213,"outputs":[]},{"cell_type":"code","source":["def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n","    '''\n","    Returns maximum value of metrics for predicition by model against\n","    multiple ground truths.\n","    \n","    :param func metric_fn: can be 'exact_match_score' or 'f1_score'\n","    :param str prediction: predicted answer span by the model\n","    :param list ground_truths: list of ground truths against which\n","                               metrics are calculated. Maximum values of \n","                               metrics are chosen.\n","                            \n","    \n","    '''\n","    scores_for_ground_truths = []\n","    for ground_truth in ground_truths:\n","        score = metric_fn(prediction, ground_truth)\n","        scores_for_ground_truths.append(score)\n","        \n","    return max(scores_for_ground_truths)"],"metadata":{"id":"oEhaluSTBz8f","executionInfo":{"status":"ok","timestamp":1647094047140,"user_tz":-420,"elapsed":6,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"execution_count":214,"outputs":[]},{"cell_type":"code","source":["def f1_score(prediction, ground_truth):\n","    '''\n","    Returns f1 score of two strings.\n","    '''\n","    prediction_tokens = normalize_answer(prediction).split()\n","    ground_truth_tokens = normalize_answer(ground_truth).split()\n","    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n","    num_same = sum(common.values())\n","    if num_same == 0:\n","        return 0\n","    precision = 1.0 * num_same / len(prediction_tokens)\n","    recall = 1.0 * num_same / len(ground_truth_tokens)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1"],"metadata":{"id":"TAAY7KiAB2UA","executionInfo":{"status":"ok","timestamp":1647094047140,"user_tz":-420,"elapsed":5,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"execution_count":215,"outputs":[]},{"cell_type":"code","source":["def exact_match_score(prediction, ground_truth):\n","    '''\n","    Returns exact_match_score of two strings.\n","    '''\n","    return (normalize_answer(prediction) == normalize_answer(ground_truth))"],"metadata":{"id":"c_qwgDCRB6LF","executionInfo":{"status":"ok","timestamp":1647094047141,"user_tz":-420,"elapsed":6,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"execution_count":216,"outputs":[]},{"cell_type":"code","execution_count":217,"metadata":{"id":"V7NQHgpE3XdI","executionInfo":{"status":"ok","timestamp":1647094047141,"user_tz":-420,"elapsed":6,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["def epoch_time(start_time, end_time):\n","    '''\n","    Helper function to record epoch time.\n","    '''\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"markdown","metadata":{"id":"2t-WNmVI3kPo"},"source":["# Training Model"]},{"cell_type":"code","execution_count":218,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90224,"status":"ok","timestamp":1647094144546,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"5HN9Oe4P3m3j","outputId":"dea47794-1356-4594-fed3-27b0bd88bad9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","Starting training ........\n","Starting batch: 0\n","Starting batch: 50\n","Starting batch: 100\n","Starting batch: 150\n","Starting batch: 200\n","Starting batch: 250\n","Starting validation .........\n","Starting batch 0\n","Epoch train loss : nan| Time: 1m 30s\n","Epoch valid loss: nan\n","Epoch EM: 2.0309477756286265\n","Epoch F1: 3.3365570599613164\n","====================================================================================\n","Total Runingtime 90.05917000770569\n"]}],"source":["start_tm = time.time()\n","\n","train_losses = []\n","valid_losses = []\n","ems = []\n","f1s = []\n","epochs = 1\n","\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch+1}\")\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_dataset)\n","    valid_loss, em, f1 = valid(model, valid_dataset)\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    ems.append(em)\n","    f1s.append(f1)\n","    \n","    print(f\"Epoch train loss : {train_loss}| Time: {epoch_mins}m {epoch_secs}s\")\n","    print(f\"Epoch valid loss: {valid_loss}\")\n","    print(f\"Epoch EM: {em}\")\n","    print(f\"Epoch F1: {f1}\")\n","    print(\"====================================================================================\")\n","\n","print(f\"Total Runingtime {time.time() - start_tm}\")"]},{"cell_type":"markdown","metadata":{"id":"h8bKj26w7P3y"},"source":["# Check Training"]},{"cell_type":"code","source":["def loopBatch(dataset,loop_n):\n","  for i,batch in enumerate(dataset):\n","    if i >loop_n:\n","      break\n","    else :\n","      context, question, context_mask, question_mask, label, context_text, answers, ids  = batch\n","  return context, question, context_mask, question_mask, label, context_text, answers, ids"],"metadata":{"id":"jCoPgUBNDBFt","executionInfo":{"status":"ok","timestamp":1647094215504,"user_tz":-420,"elapsed":391,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"execution_count":219,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda')\n","# place the tensors on GPU\n","context, question, context_mask, question_mask, label, context_text, answers, ids = loopBatch(train_dataset,3)\n","context, context_mask, question, question_mask, label = context.to(device), context_mask.to(device), question.to(device), question_mask.to(device), label.to(device)"],"metadata":{"id":"5caA3bhBDKVv","executionInfo":{"status":"ok","timestamp":1647094218378,"user_tz":-420,"elapsed":1020,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"execution_count":220,"outputs":[]},{"cell_type":"code","source":["preds = model(context, question, context_mask, question_mask)\n","start_pred, end_pred = preds\n","print(start_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39rwZUIMZf9e","executionInfo":{"status":"ok","timestamp":1647094230930,"user_tz":-420,"elapsed":480,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"fd456488-36cd-446f-c3eb-b5359b36990b"},"execution_count":221,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[nan, nan, nan,  ..., -inf, -inf, -inf],\n","        [nan, nan, nan,  ..., -inf, -inf, -inf],\n","        [nan, nan, nan,  ..., -inf, -inf, -inf],\n","        ...,\n","        [nan, nan, nan,  ..., -inf, -inf, -inf],\n","        [nan, nan, nan,  ..., -inf, -inf, -inf],\n","        [nan, nan, nan,  ..., -inf, -inf, -inf]], device='cuda:0',\n","       grad_fn=<MaskedFillBackward0>)\n"]}]},{"cell_type":"code","source":["for i in range(0,20):\n","  context, question, context_mask, question_mask, label, context_text, answers, ids = loopBatch(train_dataset,3)\n","  context, context_mask, question, question_mask, label = context.to(device), context_mask.to(device), question.to(device), question_mask.to(device), label.to(device)\n","  preds = model(context, question, context_mask, question_mask)\n","  print(f\"Batch {i} : loss : {F.cross_entropy(preds[0], label[:,0]) + F.cross_entropy(preds[1], label[:,1])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QlPLPzK3YDbc","executionInfo":{"status":"ok","timestamp":1645918820319,"user_tz":-420,"elapsed":16699,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"7f8d318a-0eb3-410c-f418-9d0681f4fb52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0 : loss : 11.424909591674805\n","Batch 1 : loss : 11.35029411315918\n","Batch 2 : loss : 11.533506393432617\n","Batch 3 : loss : 11.459067344665527\n","Batch 4 : loss : 11.364566802978516\n","Batch 5 : loss : 11.543905258178711\n","Batch 6 : loss : 11.60793399810791\n","Batch 7 : loss : 11.500799179077148\n","Batch 8 : loss : 11.467121124267578\n","Batch 9 : loss : 11.52192497253418\n","Batch 10 : loss : 11.595657348632812\n","Batch 11 : loss : 11.583470344543457\n","Batch 12 : loss : 11.617942810058594\n","Batch 13 : loss : 11.575180053710938\n","Batch 14 : loss : 11.454253196716309\n","Batch 15 : loss : 11.449477195739746\n","Batch 16 : loss : 11.552932739257812\n","Batch 17 : loss : 11.547327041625977\n","Batch 18 : loss : 11.537164688110352\n","Batch 19 : loss : 11.581380844116211\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hbD-thuQ7e9f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645918561812,"user_tz":-420,"elapsed":525,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"ff6e3778-04e0-4f9e-9e2b-f5ef4801cd2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([[ 0.2457,  0.1388, -0.0681,  ...,    -inf,    -inf,    -inf],\n","        [ 0.4133,  0.4432,  0.8993,  ...,    -inf,    -inf,    -inf],\n","        [ 0.5402,  0.2073, -0.1529,  ...,    -inf,    -inf,    -inf],\n","        ...,\n","        [ 0.2609,  0.4207, -0.2915,  ...,    -inf,    -inf,    -inf],\n","        [-0.1516, -0.5904, -0.5457,  ...,    -inf,    -inf,    -inf],\n","        [ 0.5432,  0.1943,  0.2013,  ...,    -inf,    -inf,    -inf]],\n","       device='cuda:0', grad_fn=<MaskedFillBackward0>), tensor([[-0.0410, -0.2035,  0.1451,  ...,    -inf,    -inf,    -inf],\n","        [ 0.7891,  0.3434,  0.3288,  ...,    -inf,    -inf,    -inf],\n","        [-0.2050, -0.2274, -0.6105,  ...,    -inf,    -inf,    -inf],\n","        ...,\n","        [-0.6340, -1.2802, -0.1492,  ...,    -inf,    -inf,    -inf],\n","        [-0.2392,  0.2916, -0.4470,  ...,    -inf,    -inf,    -inf],\n","        [ 0.5709, -0.0878,  0.0837,  ...,    -inf,    -inf,    -inf]],\n","       device='cuda:0', grad_fn=<MaskedFillBackward0>))\n","tensor(11.4667, device='cuda:0', grad_fn=<AddBackward0>)\n"]}],"source":["# forward pass, get the predictions\n","preds = model(context, question, context_mask, question_mask)\n","start_pred, end_pred = preds\n","print(preds)\n","        \n","# separate labels for start and end position\n","start_label, end_label = label[:,0], label[:,1]\n","        \n","# calculate loss\n","loss = F.cross_entropy(start_pred, start_label) + F.cross_entropy(end_pred, end_label)\n","print(loss)"]},{"cell_type":"code","source":["def tune_embedding(grad, words=1000):\n","    grad[words:] = 0\n","    return grad"],"metadata":{"id":"e-6eat6_N8cr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights_matrix).to(device),freeze=False ,padding_idx=0)\n","embedding.weight.register_hook(tune_embedding)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W9Qn27PREjFv","executionInfo":{"status":"ok","timestamp":1645917861811,"user_tz":-420,"elapsed":420,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"547a6b8b-8c4e-48ab-d939-645466a2e06a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.utils.hooks.RemovableHandle at 0x7fcc30b0af50>"]},"metadata":{},"execution_count":136}]},{"cell_type":"code","source":["ctx_embed = embedding(context).to(device)\n","ques_embed = embedding(question).to(device)\n","dropout = nn.Dropout(0.3)\n","ctx_embed = dropout(ctx_embed).to(device)\n","ques_embed = dropout(ques_embed).to(device)\n","print(f\"Size of ctx_embed {ctx_embed.size()}\")\n","print(f\"Size of ques_embed {ques_embed.size()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fV39NZyiFLnX","executionInfo":{"status":"ok","timestamp":1645917865210,"user_tz":-420,"elapsed":2,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"02057f31-2ca5-41e2-bf6c-4e7eda14b35d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of ctx_embed torch.Size([32, 774, 300])\n","Size of ques_embed torch.Size([32, 30, 300])\n"]}]},{"cell_type":"code","source":["align_embedding = AlignQuestionEmbedding(300).to(device)\n","align_embed = align_embedding(ctx_embed, ques_embed, question_mask)"],"metadata":{"id":"VFa0CIXrE3Z1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ctx_bilstm_input = torch.cat([ctx_embed, align_embed], dim=2)"],"metadata":{"id":"YZwTPBXYLIqG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["context_bilstm = StackedBiLSTM(300 * 2, 128, 1, 0.3).to(device)\n","ctx_outputs = context_bilstm(ctx_bilstm_input)"],"metadata":{"id":"NqJN0y06LWpW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question_bilstm = StackedBiLSTM(300, 128, 1, 0.3).to(device)\n","qtn_outputs = question_bilstm(ques_embed)\n","print(f\"Size of qtn_outputs {qtn_outputs.size()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVPGFgsuL1QC","executionInfo":{"status":"ok","timestamp":1645916855525,"user_tz":-420,"elapsed":9,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"dd669ed5-f92d-461c-c26d-1230100240cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of qtn_outputs torch.Size([32, 30, 256])\n"]}]},{"cell_type":"code","source":["linear_attn_question = LinearAttentionLayer(128*1*2) .to(device)\n","qtn_weights = linear_attn_question(qtn_outputs, question_mask)\n","print(f\"Size of qtn_weights {qtn_weights.size()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N8Pe9DBjMRCx","executionInfo":{"status":"ok","timestamp":1645916856638,"user_tz":-420,"elapsed":7,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"5b77f16d-e639-46a6-8541-09b165508b2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of qtn_weights torch.Size([32, 30])\n"]}]},{"cell_type":"code","source":["qtn_weighted = weighted_average(qtn_outputs, qtn_weights)\n","print(f\"Size of qtn_weighted {qtn_weighted.size()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kGOftGkfMeCc","executionInfo":{"status":"ok","timestamp":1645916858206,"user_tz":-420,"elapsed":9,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"d43bfe65-d651-45ba-c00e-9dd573f3260a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of qtn_weighted torch.Size([32, 256])\n"]}]},{"cell_type":"code","source":["bilinear_attn_start = BilinearAttentionLayer(128*1*2, 128*1*2).to(device)\n","start_scores = bilinear_attn_start(ctx_outputs, qtn_weighted, context_mask)"],"metadata":{"id":"SENXTB6QM2TW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bilinear_attn_end = BilinearAttentionLayer(128*1*2, 128*1*2).to(device)\n","end_scores = bilinear_attn_end(ctx_outputs, qtn_weighted, context_mask)"],"metadata":{"id":"Z347sI65NcDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["F.cross_entropy(start_scores, start_label) + F.cross_entropy(end_scores, end_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pK5TmmvpNqig","executionInfo":{"status":"ok","timestamp":1645916863295,"user_tz":-420,"elapsed":10,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"e4908de8-36b3-49ea-e86e-a1b1a958410f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(11.7582, device='cuda:0', grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":125}]},{"cell_type":"code","source":["start_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-JxFgXLSqfl","executionInfo":{"status":"ok","timestamp":1645916893646,"user_tz":-420,"elapsed":5,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"a8ed9312-dd3c-4cca-f390-2c7d01f40394"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.3630, -0.2777, -0.1493,  ...,    -inf,    -inf,    -inf],\n","        [-0.2866, -0.0476, -0.4334,  ...,    -inf,    -inf,    -inf],\n","        [ 0.0096, -0.0054,  0.1559,  ...,    -inf,    -inf,    -inf],\n","        ...,\n","        [ 0.6172,  0.6508,  0.3309,  ...,    -inf,    -inf,    -inf],\n","        [-0.6726, -0.2234,  0.0203,  ...,    -inf,    -inf,    -inf],\n","        [-0.8651, -0.4073, -0.6602,  ...,    -inf,    -inf,    -inf]],\n","       device='cuda:0', grad_fn=<MaskedFillBackward0>)"]},"metadata":{},"execution_count":127}]},{"cell_type":"code","source":["start_label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SH9CxeTfSob6","executionInfo":{"status":"ok","timestamp":1645916885351,"user_tz":-420,"elapsed":9,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"f5dae3a8-a3c3-4f5f-e4c6-ec6583f7e1ea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([133, 272,  24,   0,  96,  33,  27,  18,  11,  35, 329, 303, 187,  13,\n","         47, 159,  33,  58, 145,  15,   0, 112,  99,  42,  93,  64,  18,  15,\n","        342,  18,   0,  33], device='cuda:0')"]},"metadata":{},"execution_count":126}]},{"cell_type":"code","source":["EMB_DIM = 300\n","HIDDEN_DIM = 128\n","NUM_LAYERS = 1\n","NUM_DIRECTIONS = 2\n","DROPOUT = 0.3"],"metadata":{"id":"1MbnnYCkLlKv"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":["qUSjaq2C0Xdl","9-Ov1HJ10cSr","z_Ui7-6r3Lzy"],"machine_shape":"hm","name":"model_reader.ipynb","provenance":[],"authorship_tag":"ABX9TyPkGfMk/enSAy8hjrERz6ub"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}