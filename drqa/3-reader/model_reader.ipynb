{"cells":[{"cell_type":"markdown","metadata":{"id":"0xt-OBYF0SoN"},"source":["# Set Environment"]},{"cell_type":"markdown","metadata":{"id":"qUSjaq2C0Xdl"},"source":["## import package"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3841,"status":"ok","timestamp":1646999075750,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"TRBC-EUE487p","outputId":"604ea66d-1a2f-414a-94e9-04b7f3fbfa44"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pythainlp\n","  Downloading pythainlp-3.0.5-py3-none-any.whl (11.5 MB)\n","\u001b[K     |████████████████████████████████| 11.5 MB 15.3 MB/s \n","\u001b[?25hCollecting tinydb>=3.0\n","  Downloading tinydb-4.7.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n","Requirement already satisfied: typing-extensions<5.0.0,>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from tinydb>=3.0->pythainlp) (3.10.0.2)\n","Installing collected packages: tinydb, pythainlp\n","Successfully installed pythainlp-3.0.5 tinydb-4.7.0\n"]}],"source":["!pip install pythainlp"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"4TlOpoFD0Dhp","executionInfo":{"status":"ok","timestamp":1646999086708,"user_tz":-420,"elapsed":10961,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torchtext\n","import torch\n","import time\n","from torch import nn\n","import json, re, unicodedata, string, typing, time\n","import torch.nn.functional as F\n","import spacy\n","from collections import Counter\n","import pickle\n","from pythainlp.tokenize import word_tokenize\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"9-Ov1HJ10cSr"},"source":["## mount google drive"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18632,"status":"ok","timestamp":1646999105323,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"O-p2gMyc0VsH","outputId":"4d926a36-bd3f-4664-c9e3-e35de9d3e95b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#mount my google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":658,"status":"ok","timestamp":1646999105973,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"HJvZp-V60tov","outputId":"4c63015b-839b-4af1-a130-a38a01fcc0d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/BADS9000_IS/Colab-DrQA\n"]}],"source":["%cd /content/drive/MyDrive/Colab Notebooks/BADS9000_IS/Colab-DrQA"]},{"cell_type":"markdown","metadata":{"id":"v15bqdFi0x60"},"source":["# Load Data"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"fQr6hmZ_1K4I","executionInfo":{"status":"ok","timestamp":1646999105975,"user_tz":-420,"elapsed":14,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["def load_pickle(path_file):\n","    with open(path_file, 'rb') as file:\n","        load_obj = pickle.load(file)\n","        print(f\"load object from {path_file} success,that is {type(load_obj)}\")\n","        return load_obj"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26364,"status":"ok","timestamp":1646999132328,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"rIRTAEoL00jS","outputId":"9ede40c6-b9e6-442f-88bc-a291e641e16f"},"outputs":[{"output_type":"stream","name":"stdout","text":["load object from ./drqa/1-tokenizers/result/df_qa.pkl success,that is <class 'pandas.core.frame.DataFrame'>\n","load object from ./drqa/1-tokenizers/result/dict_word2idx.pkl success,that is <class 'dict'>\n","load object from ./drqa/1-tokenizers/result/dict_idx2word.pkl success,that is <class 'dict'>\n","load object from ./drqa/1-tokenizers/result/list_word_vocab.pkl success,that is <class 'list'>\n","load object from ./drqa/1-tokenizers/result/dict_embed_ltw2v.pkl success,that is <class 'dict'>\n","CPU times: user 2.27 s, sys: 1.29 s, total: 3.55 s\n","Wall time: 26.3 s\n"]}],"source":["%%time\n","df_qa = load_pickle(\"./drqa/1-tokenizers/result/df_qa.pkl\")\n","word2idx = load_pickle(\"./drqa/1-tokenizers/result/dict_word2idx.pkl\")\n","idx2word  = load_pickle(\"./drqa/1-tokenizers/result/dict_idx2word.pkl\")\n","word_vocab = load_pickle(\"./drqa/1-tokenizers/result/list_word_vocab.pkl\")\n","glove_dict =  load_pickle(\"./drqa/1-tokenizers/result/dict_embed_ltw2v.pkl\")\n","weights_matrix = np.load('./drqa/1-tokenizers/result/dfqa2v_ltw2v.npy')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1646999132329,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"tO_2Q4EGLHiS","outputId":"5ad5cb83-06ca-4582-cb1d-1b11571c2d05"},"outputs":[{"output_type":"stream","name":"stdout","text":["number of element in dict 731,185\n","shape of element in dict (300,)\n","type of element in dict <class 'numpy.ndarray'>\n","number of word not found in dict : 8,005\n"]}],"source":["print(f\"number of element in dict {len(glove_dict):0,.0f}\")\n","print(f\"shape of element in dict {glove_dict['that'].shape}\")\n","print(f\"type of element in dict {type(glove_dict['that'])}\")\n","print(f\"number of word not found in dict : {np.sum(weights_matrix.sum(axis=1)==0):0,.0f}\")"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1646999814404,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"NFVFfAjG1Wjl","outputId":"80920cda-e3d1-4386-d142-566adf9f8ceb"},"outputs":[{"output_type":"stream","name":"stdout","text":["type(train_df):<class 'pandas.core.frame.DataFrame'>, train_df.shape:(2327, 8), #columns:8\n","type(valid_df):<class 'pandas.core.frame.DataFrame'>, valid_df.shape:(259, 8), #columns:8\n"]}],"source":["from sklearn.model_selection import train_test_split\n","df_qa = df_qa[df_qa.context_ids.apply(lambda x:len(x))<1000][['id', 'context', 'question', 'label', 'answer', 'context_ids', 'question_ids', 'label_idx']].reset_index(drop=True)\n","train_df, valid_df = train_test_split(df_qa, test_size=0.1 , random_state=12345)\n","train_df = train_df.reset_index(drop=True)\n","valid_df = valid_df.reset_index(drop=True)\n","print(f\"type(train_df):{type(train_df)}, train_df.shape:{train_df.shape}, #columns:{len(train_df.columns)}\")\n","print(f\"type(valid_df):{type(valid_df)}, valid_df.shape:{valid_df.shape}, #columns:{len(valid_df.columns)}\")"]},{"cell_type":"markdown","metadata":{"id":"XUhnn56g0wk9"},"source":["# Create Torch Batch"]},{"cell_type":"markdown","source":["## Built"],"metadata":{"id":"PMVbsaU8pvVj"}},{"cell_type":"code","execution_count":65,"metadata":{"id":"WQDzsUm_2UqS","executionInfo":{"status":"ok","timestamp":1646999829266,"user_tz":-420,"elapsed":7,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["class SquadDataset:\n","    '''\n","    -Divides the dataframe in batches.\n","    -Pads the contexts and questions dynamically for each batch by padding \n","     the examples to the maximum-length sequence in that batch.\n","    -Calculates masks for context and question.\n","    -Calculates spans for contexts.\n","    '''\n","    \n","    def __init__(self, data, batch_size):\n","        \n","        self.batch_size = batch_size\n","        data = [data[i:i+self.batch_size] for i in range(0, len(data), self.batch_size)]\n","        self.data = data\n","    \n","    def get_span(self, text):\n","        \n","        lst_token = word_tokenize(text ,engine='newmm')\n","        span  = [(len(\"\".join(lst_token[0:i])), len(\"\".join(lst_token[0:i+1]))) \n","                         for i,w in enumerate(lst_token)]\n","        return span\n","\n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __iter__(self):\n","        '''\n","        Creates batches of data and yields them.\n","        \n","        Each yield comprises of:\n","        :padded_context: padded tensor of contexts for each batch \n","        :padded_question: padded tensor of questions for each batch \n","        :context_mask & question_mask: zero-mask for question and context\n","        :label: start and end index wrt context_ids\n","        :context_text,answer_text: used while validation to calculate metrics\n","        :context_spans: spans of context text\n","        :ids: question_ids used in evaluation\n","        '''\n","        \n","        for batch in self.data:\n","                            \n","            spans = []\n","            context_text = []\n","            answer_text = []\n","            \n","            max_context_len = max([len(ctx) for ctx in batch.context_ids])\n","            padded_context = torch.LongTensor(len(batch), max_context_len).fill_(1)\n","            context_mask = torch.ByteTensor(len(batch), max_context_len).fill_(1)\n","            \n","            for ctx in batch.context:\n","                context_text.append(ctx)\n","                spans.append(self.get_span(ctx))\n","            \n","            for ans in batch.answer:\n","                answer_text.append(ans)\n","                \n","            for i, ctx in enumerate(batch.context_ids):\n","                padded_context[i, :len(ctx)] = torch.LongTensor(ctx)\n","                context_mask[i, :len(ctx)].fill_(0)\n","            \n","            max_question_len = max([len(ques) for ques in batch.question_ids])\n","            padded_question = torch.LongTensor(len(batch), max_question_len).fill_(1)\n","            question_mask = torch.ByteTensor(len(batch), max_question_len).fill_(1)\n","            \n","            for i, ques in enumerate(batch.question_ids):\n","                padded_question[i,: len(ques)] = torch.LongTensor(ques)\n","                question_mask[i, :len(ques)].fill_(0)\n","                \n","            \n","            label = torch.LongTensor(list(batch.label_idx))\n","            context_mask = torch.eq(context_mask, 1)\n","            question_mask = torch.eq(question_mask, 1)\n","            \n","            ids = list(batch.id)  \n","            \n","            yield (padded_context, padded_question, context_mask, \n","                   question_mask, label, context_text, answer_text, ids)"]},{"cell_type":"code","source":["#if maximum number of token is too big, it use more GPU\n","# context_ids , question_ids are to big, it have size 200K when in english have size 810\n","print(f\"maximum number of token in question_ids : {train_df.context_ids.apply(lambda x:len(x)).max()}\")\n","print(f\"maximum number of token in question_ids : {train_df.question_ids.apply(lambda x:len(x)).max()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16HD790QdieB","executionInfo":{"status":"ok","timestamp":1646999829777,"user_tz":-420,"elapsed":18,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"b3c66960-3e11-43ea-a5fd-9f846324fae1"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["maximum number of token in question_ids : 845\n","maximum number of token in question_ids : 38\n"]}]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1646999897247,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"SKPAebdo2Z46","outputId":"b65f3168-385e-45be-fe05-70b311e328b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n","Wall time: 5.72 µs\n","type(train_dataset):<class '__main__.SquadDataset'>\n","type(valid_dataset):<class '__main__.SquadDataset'>\n"]}],"source":["%time\n","train_dataset = SquadDataset(train_df, 8)\n","valid_dataset = SquadDataset(valid_df, 8)\n","print(f\"type(train_dataset):{type(train_dataset)}\")\n","print(f\"type(valid_dataset):{type(valid_dataset)}\")"]},{"cell_type":"markdown","source":["## Explore Function"],"metadata":{"id":"0YqC6MDCpm_U"}},{"cell_type":"code","execution_count":68,"metadata":{"executionInfo":{"elapsed":823,"status":"ok","timestamp":1646999830589,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"Rd3R23sH2dv3"},"outputs":[],"source":["padded_context, padded_question, context_mask, question_mask, label, context_text, answer_text, ids = next(iter(train_dataset))"]},{"cell_type":"code","source":["train_df.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"9o5NZY1jmxYd","executionInfo":{"status":"ok","timestamp":1646999830590,"user_tz":-420,"elapsed":52,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"c1a97cf8-a03c-418e-fcf5-2eb59b877980"},"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-dc645a9d-ed88-49c9-9602-0a5fad7bdfe7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>label</th>\n","      <th>answer</th>\n","      <th>context_ids</th>\n","      <th>question_ids</th>\n","      <th>label_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>405</td>\n","      <td>ซูสีไทเฮา เดอะมิวสิคัล ซูสีไทเฮา เดอะมิวสิคัล ...</td>\n","      <td>ผู้ที่รับบทเป็นซูสีไทเฮาในละครเวทีเรื่องซูสีไท...</td>\n","      <td>[281, 302]</td>\n","      <td>กานดา วิทยานุภาพยืนยง</td>\n","      <td>[811, 161, 8247, 0, 459, 3309, 0, 811, 161, 82...</td>\n","      <td>[66, 4, 94, 6, 811, 161, 8247, 1, 1308, 56, 81...</td>\n","      <td>[65, 70]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc645a9d-ed88-49c9-9602-0a5fad7bdfe7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dc645a9d-ed88-49c9-9602-0a5fad7bdfe7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dc645a9d-ed88-49c9-9602-0a5fad7bdfe7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    id                                            context  \\\n","0  405  ซูสีไทเฮา เดอะมิวสิคัล ซูสีไทเฮา เดอะมิวสิคัล ...   \n","\n","                                            question       label  \\\n","0  ผู้ที่รับบทเป็นซูสีไทเฮาในละครเวทีเรื่องซูสีไท...  [281, 302]   \n","\n","                  answer                                        context_ids  \\\n","0  กานดา วิทยานุภาพยืนยง  [811, 161, 8247, 0, 459, 3309, 0, 811, 161, 82...   \n","\n","                                        question_ids label_idx  \n","0  [66, 4, 94, 6, 811, 161, 8247, 1, 1308, 56, 81...  [65, 70]  "]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["padded_context[0][~context_mask[0]] "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GaUGZ5Crl85m","executionInfo":{"status":"ok","timestamp":1646999830591,"user_tz":-420,"elapsed":47,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"2e179268-da90-4af9-a860-84fed5ca3b69"},"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([  811,   161,  8247,     0,   459,  3309,     0,   811,   161,  8247,\n","            0,   459,  3309,     0,     6,  1308,     0,    17,     0,   251,\n","            0, 27431,     0,  9442,     0,   238,     0, 11039,     0,  1620,\n","           16,  2794,    62,   442,     0,     5,   650,  4799,     0,  3434,\n","          216,   216,    12,     0,     3,     0,  6457,     0,    59,    94,\n","            6,     0,   241,  2059,  4077,  8523,     0,  2431,     5,   811,\n","          161,  8247,     0,     3,     0, 15421,     0,  1459,   880,   408,\n","         8439,     0,    94,     0,   811,   161,  8247,     0,     3,     0,\n","          303,  9128,     0, 35934,  6688,     0,    94,     0,   222,  4748,\n","         1466,     0,  9684,  9328,     5,   811,   161,  8247,     0,     3,\n","            0,   303,  2984,     0,  7155,     0,    94,     0,   662,   914,\n","        35935,     0,     3,     0,   923,   388,   513,     0,  1147, 10535,\n","            0,    94,     0,  3361,  1223,     0,     3,     0,  1987,   879,\n","            0,  3749, 35936,     0,    94,     0,   811,   209,  8247,    92])"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["padded_question[0][~question_mask[0]]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b6Mj6Me3l88l","executionInfo":{"status":"ok","timestamp":1646999830592,"user_tz":-420,"elapsed":45,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"8246b4d6-bb88-40b4-f8d4-62c1be533484"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([  66,    4,   94,    6,  811,  161, 8247,    1, 1308,   56,  811,  161,\n","        8247,    0,  459, 3309,    0,   31,  264])"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["for i in padded_context[0][label[0][0]:label[0][1]+1]:\n","  print(f\"{i} : {idx2word[i.item()]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YBq8pv9pl9AD","executionInfo":{"status":"ok","timestamp":1646999830593,"user_tz":-420,"elapsed":44,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"505d3906-b2e1-4271-caaa-eb2841487a49"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["15421 : กานดา\n","0 :  \n","1459 : วิทยา\n","880 : นุ\n","408 : ภาพ\n","8439 : ยืนยง\n"]}]},{"cell_type":"code","source":["train_df[train_df.id == ids[3]]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"9ar9NSral9Ic","executionInfo":{"status":"ok","timestamp":1646999830594,"user_tz":-420,"elapsed":43,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"2f5b1ba0-5ef1-436e-d9e3-592ada07676e"},"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-60ebcd54-2b8a-44da-b15d-a413c7910c81\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>label</th>\n","      <th>answer</th>\n","      <th>context_ids</th>\n","      <th>question_ids</th>\n","      <th>label_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>2762</td>\n","      <td>แคมป์เลกบ็อตทอม แคมป์เลกบ็อตทอม () เป็นการ์ตูน...</td>\n","      <td>แคมป์เลกบ็อตทอมเป็นการ์ตูนทีวีแอนิเมชันของประเ...</td>\n","      <td>[68, 74]</td>\n","      <td>แคนาดา</td>\n","      <td>[10414, 8979, 15680, 3778, 0, 10414, 8979, 156...</td>\n","      <td>[10414, 8979, 15680, 3778, 6, 900, 1094, 3628,...</td>\n","      <td>[18, 18]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60ebcd54-2b8a-44da-b15d-a413c7910c81')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-60ebcd54-2b8a-44da-b15d-a413c7910c81 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-60ebcd54-2b8a-44da-b15d-a413c7910c81');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     id                                            context  \\\n","3  2762  แคมป์เลกบ็อตทอม แคมป์เลกบ็อตทอม () เป็นการ์ตูน...   \n","\n","                                            question     label  answer  \\\n","3  แคมป์เลกบ็อตทอมเป็นการ์ตูนทีวีแอนิเมชันของประเ...  [68, 74]  แคนาดา   \n","\n","                                         context_ids  \\\n","3  [10414, 8979, 15680, 3778, 0, 10414, 8979, 156...   \n","\n","                                        question_ids label_idx  \n","3  [10414, 8979, 15680, 3778, 6, 900, 1094, 3628,...  [18, 18]  "]},"metadata":{},"execution_count":73}]},{"cell_type":"markdown","source":["# Create Layer function"],"metadata":{"id":"ycQcxXYIBEgH"}},{"cell_type":"markdown","source":["## AlignQuestionEmbedding"],"metadata":{"id":"G3kWeo9K4iSa"}},{"cell_type":"code","execution_count":74,"metadata":{"id":"3A2FYP2U2hDI","executionInfo":{"status":"ok","timestamp":1646999833352,"user_tz":-420,"elapsed":9,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["class AlignQuestionEmbedding(nn.Module): #SeqAttnMatch\n","    \n","    def __init__(self, input_dim):        \n","        \n","        super().__init__()\n","        \n","        self.linear = nn.Linear(input_dim, input_dim)\n","        \n","        self.relu = nn.ReLU()\n","        \n","    def forward(self, x, y, y_mask):\n","\n","      # Args:\n","      # x - context: [bs, ctx_len, emb_dim]\n","      # y - question:[bs, qtn_len, emb_dim]\n","      # y_mask -question_mask : [bs, qtn_len]\n","      # Output:\n","      # matched_seq: [bs, ctx_len, emb_dim]\n","\n","        \n","        # Project vectors\n","        x_proj = self.linear(x.view(-1, x.size(2))).view(x.size())\n","        x_proj = F.relu(x_proj)\n","        y_proj = self.linear(y.view(-1, y.size(2))).view(y.size())\n","        y_proj = F.relu(y_proj)\n","        \n","        # Compute scores\n","        scores = x_proj.bmm(y_proj.transpose(2, 1))\n","        # Mask padding\n","        y_mask = y_mask.unsqueeze(1).expand(scores.size())\n","        scores.data.masked_fill_(y_mask.data, -float('inf'))\n","        # Normalize with softmax\n","        alpha_flat = F.softmax(scores.view(-1, y.size(1)), dim=-1)\n","        alpha = alpha_flat.view(-1, x.size(1), y.size(1))\n","        # Take weighted average\n","        matched_seq = alpha.bmm(y)\n","        \n","        return matched_seq"]},{"cell_type":"markdown","source":["## StackedBiLSTM"],"metadata":{"id":"8rpeJq_S4m7S"}},{"cell_type":"code","execution_count":75,"metadata":{"id":"hHTKEop52pMB","executionInfo":{"status":"ok","timestamp":1646999835200,"user_tz":-420,"elapsed":7,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["class StackedBiLSTM(nn.Module): #StackedBRNN\n","    \n","    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n","        \n","        super().__init__()\n","        \n","        self.dropout = dropout\n","        \n","        self.num_layers = num_layers\n","        \n","        self.lstms = nn.ModuleList()\n","        \n","        for i in range(self.num_layers):\n","            \n","            input_dim = input_dim if i == 0 else hidden_dim * 2\n","            self.lstms.append(nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True))\n","           \n","    \n","    def forward(self, x):\n","        # x = [bs, seq_len, feature_dim]\n","\n","        outputs = [x]\n","        for i in range(self.num_layers):\n","\n","            lstm_input = outputs[-1]\n","            lstm_input = F.dropout(lstm_input, p=self.dropout) #<<<??\n","            lstm_out, (hidden, cell) = self.lstms[i](lstm_input)\n","           \n","            outputs.append(lstm_out)\n","\n","    \n","        output = torch.cat(outputs[1:], dim=2)\n","        # [bs, seq_len, num_layers*num_dir*hidden_dim]\n","        \n","        # output = output.transpose(0, 1) ??\n","        output = F.dropout(output, p=self.dropout)\n","      \n","        return output"]},{"cell_type":"markdown","source":["## LinearAttentionLayer"],"metadata":{"id":"T0ffu2t_4pmz"}},{"cell_type":"code","execution_count":76,"metadata":{"id":"m9hl1zqi2uCW","executionInfo":{"status":"ok","timestamp":1646999836874,"user_tz":-420,"elapsed":11,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["class LinearAttentionLayer(nn.Module): #LinearSeqAttn\n","    \n","    def __init__(self, input_dim):\n","        \n","        super().__init__()\n","        \n","        self.linear = nn.Linear(input_dim, 1)\n","        \n","    def forward(self, question, question_mask):\n","        \n","        # question = [bs, qtn_len, input_dim] = [bs, qtn_len, bi_lstm_hid_dim]\n","        # question_mask = [bs,  qtn_len]\n","        \n","        qtn = question.view(-1, question.shape[-1])\n","        # qtn = [bs*qtn_len, hid_dim]\n","        \n","        attn_scores = self.linear(qtn)\n","        # attn_scores = [bs*qtn_len, 1]\n","        \n","        attn_scores = attn_scores.view(question.shape[0], question.shape[1])\n","        # attn_scores = [bs, qtn_len]\n","        \n","        attn_scores = attn_scores.masked_fill(question_mask == 1, -float('inf'))\n","        \n","        alpha = F.softmax(attn_scores, dim=1)\n","        # alpha = [bs, qtn_len]\n","        \n","        return alpha\n","        "]},{"cell_type":"code","execution_count":77,"metadata":{"id":"xMAiQuaQ2wlW","executionInfo":{"status":"ok","timestamp":1646999836876,"user_tz":-420,"elapsed":9,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["def weighted_average(x, weights):\n","    # x = [bs, len, dim]\n","    # weights = [bs, len]\n","    \n","    weights = weights.unsqueeze(1)\n","    # weights = [bs, 1, len]\n","    \n","    w = weights.bmm(x).squeeze(1)\n","    # w = [bs, 1, dim] => [bs, dim]\n","    \n","    return w"]},{"cell_type":"markdown","source":["## BilinearAttentionLayer"],"metadata":{"id":"Wr2v-BJK4qg8"}},{"cell_type":"code","execution_count":78,"metadata":{"id":"K-cDhxpt20w9","executionInfo":{"status":"ok","timestamp":1646999839728,"user_tz":-420,"elapsed":434,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["class BilinearAttentionLayer(nn.Module): #BilinearSeqAttn\n","    \n","    def __init__(self, context_dim, question_dim):\n","        \n","        super().__init__()\n","        \n","        self.linear = nn.Linear(question_dim, context_dim)\n","        \n","    def forward(self, context, question, context_mask):\n","        \n","        # context = [bs, ctx_len, ctx_hid_dim] = [bs, ctx_len, hid_dim*6] = [bs, ctx_len, 768]\n","        # question = [bs, qtn_hid_dim] = [bs, qtn_len, 768]\n","        # context_mask = [bs, ctx_len]\n","        \n","        qtn_proj = self.linear(question)\n","        # qtn_proj = [bs, ctx_hid_dim]\n","        \n","        qtn_proj = qtn_proj.unsqueeze(2)\n","        # qtn_proj = [bs, ctx_hid_dim, 1]\n","        \n","        scores = context.bmm(qtn_proj)\n","        # scores = [bs, ctx_len, 1]\n","        \n","        scores = scores.squeeze(2)\n","        # scores = [bs, ctx_len]\n","        \n","        scores = scores.masked_fill(context_mask == 1, -float('inf'))\n","        \n","        alpha = F.log_softmax(scores, dim=1) # In training and normalize we output log-softmax for NLL\n","        \n","        # alpha = F.log_softmax(scores, dim=-1) # normalize Otherwise 0-1 probabilities\n","        # alpha = xWy.exp() # non normalize\n","        # alpha = [bs, ctx_len]\n","        \n","        return alpha"]},{"cell_type":"markdown","source":["# Create Model"],"metadata":{"id":"iCE-4y01BTgb"}},{"cell_type":"markdown","source":["## DocumentReader"],"metadata":{"id":"MCE3wZTMBXwm"}},{"cell_type":"code","execution_count":79,"metadata":{"id":"JGIVpX8f26BS","executionInfo":{"status":"ok","timestamp":1646999848502,"user_tz":-420,"elapsed":502,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["class DocumentReader(nn.Module):\n","    \n","    def __init__(self, hidden_dim, embedding_dim, num_layers, num_directions, dropout, device):\n","        \n","        super().__init__()\n","        \n","        self.device = device\n","        \n","        #self.embedding = self.get_glove_embedding()\n","        \n","        self.context_bilstm = StackedBiLSTM(embedding_dim * 2, hidden_dim, num_layers, dropout)\n","        \n","        self.question_bilstm = StackedBiLSTM(embedding_dim, hidden_dim, num_layers, dropout)\n","        \n","        self.glove_embedding = self.get_glove_embedding()\n","        \n","        def tune_embedding(grad, words=61036):\n","            grad[words:] = 0\n","            return grad\n","        \n","        #self.glove_embedding.weight.register_hook(tune_embedding)\n","        \n","        self.align_embedding = AlignQuestionEmbedding(embedding_dim)\n","        \n","        self.linear_attn_question = LinearAttentionLayer(hidden_dim*num_layers*num_directions) \n","        \n","        self.bilinear_attn_start = BilinearAttentionLayer(hidden_dim*num_layers*num_directions, \n","                                                          hidden_dim*num_layers*num_directions)\n","        \n","        self.bilinear_attn_end = BilinearAttentionLayer(hidden_dim*num_layers*num_directions,\n","                                                        hidden_dim*num_layers*num_directions)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","   \n","        \n","    def get_glove_embedding(self):\n","        \n","        weights_matrix = np.load('./drqa/1-tokenizers/result/dfqa2v_ltw2v.npy')\n","        num_embeddings, embedding_dim = weights_matrix.shape\n","        embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights_matrix).to(self.device),freeze=False ,padding_idx=0)\n","\n","        return embedding\n","    \n","    \n","    def forward(self, context, question, context_mask, question_mask):\n","       \n","        # context = [bs, len_c]\n","        # question = [bs, len_q]\n","        # context_mask = [bs, len_c]\n","        # question_mask = [bs, len_q]\n","        \n","        \n","        ctx_embed = self.glove_embedding(context)\n","        # ctx_embed = [bs, len_c, emb_dim]\n","        \n","        ques_embed = self.glove_embedding(question)\n","        # ques_embed = [bs, len_q, emb_dim]\n","        \n","\n","        ctx_embed = self.dropout(ctx_embed)\n","     \n","        ques_embed = self.dropout(ques_embed)\n","             \n","        align_embed = self.align_embedding(ctx_embed, ques_embed, question_mask)\n","        # align_embed = [bs, len_c, emb_dim]  \n","        \n","        ctx_bilstm_input = torch.cat([ctx_embed, align_embed], dim=2)\n","        # ctx_bilstm_input = [bs, len_c, emb_dim*2]\n","                \n","        ctx_outputs = self.context_bilstm(ctx_bilstm_input)\n","        # ctx_outputs = [bs, len_c, hid_dim*layers*dir] = [bs, len_c, hid_dim*6]\n","       \n","        qtn_outputs = self.question_bilstm(ques_embed)\n","        # qtn_outputs = [bs, len_q, hid_dim*6]\n","    \n","        qtn_weights = self.linear_attn_question(qtn_outputs, question_mask)\n","        # qtn_weights = [bs, len_q]\n","            \n","        qtn_weighted = weighted_average(qtn_outputs, qtn_weights)\n","        # qtn_weighted = [bs, hid_dim*6]\n","        \n","        start_scores = self.bilinear_attn_start(ctx_outputs, qtn_weighted, context_mask)\n","        # start_scores = [bs, len_c]\n","         \n","        end_scores = self.bilinear_attn_end(ctx_outputs, qtn_weighted, context_mask)\n","        # end_scores = [bs, len_c]\n","        \n","      \n","        return start_scores, end_scores"]},{"cell_type":"markdown","metadata":{"id":"z_Ui7-6r3Lzy"},"source":["## Model Setting"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"xWQTTv0g3OSa","executionInfo":{"status":"ok","timestamp":1646999915972,"user_tz":-420,"elapsed":429,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["device = torch.device('cuda')\n","EMB_DIM = 300\n","HIDDEN_DIM = 128\n","NUM_LAYERS = 3\n","NUM_DIRECTIONS = 2\n","DROPOUT = 0.3\n","device = torch.device('cuda')\n","\n","model = DocumentReader(HIDDEN_DIM, EMB_DIM,  NUM_LAYERS,  NUM_DIRECTIONS,  DROPOUT,  device).to(device)"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"MVPCFwjH3Vk-","executionInfo":{"status":"ok","timestamp":1646999916416,"user_tz":-420,"elapsed":7,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["optimizer = torch.optim.Adamax(model.parameters())"]},{"cell_type":"code","execution_count":84,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1646999916418,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"iSCuqHql3XM6","outputId":"0ccac924-25ea-4639-9cd0-b80685478b11"},"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 22,351,949 trainable parameters\n"]}],"source":["def count_parameters(model):\n","    '''Returns the number of trainable parameters in the model.'''\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"]},{"cell_type":"markdown","metadata":{"id":"EaD2ccj13Reb"},"source":["# Create Model Training Flow"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"huVw5nOs3XTX","executionInfo":{"status":"ok","timestamp":1646999932677,"user_tz":-420,"elapsed":518,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["def train(model, train_dataset):\n","    '''\n","    Trains the model.\n","    '''\n","    \n","    print(\"Starting training ........\")\n","    \n","    train_loss = 0.\n","    batch_count = 0\n","    \n","    # put the model in training mode\n","    model.train()\n","    \n","    # iterate through training data\n","    for batch in train_dataset:\n","\n","        if batch_count % 50 == 0:\n","            print(f\"Starting batch: {batch_count}\")\n","        batch_count += 1\n","\n","        context, question, context_mask, question_mask, label, ctx, ans, ids = batch\n","        \n","        # place the tensors on GPU\n","        context, context_mask, question, question_mask, label = context.to(device), context_mask.to(device),\\\n","                                    question.to(device), question_mask.to(device), label.to(device)\n","        \n","        # forward pass, get the predictions\n","        preds = model(context, question, context_mask, question_mask)\n","\n","        start_pred, end_pred = preds\n","        \n","        # separate labels for start and end position\n","        start_label, end_label = label[:,0], label[:,1]\n","        \n","        # calculate loss\n","        loss = F.nll_loss(start_pred, start_label) + F.nll_loss(end_pred, end_label)\n","        \n","        # backward pass, calculates the gradients\n","        loss.backward()\n","        \n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n","        \n","        # update the gradients\n","        optimizer.step()\n","        \n","        # zero the gradients to prevent them from accumulating\n","        optimizer.zero_grad()\n","\n","        train_loss += loss.item()\n","\n","    return train_loss/len(train_dataset)"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"1i090lL03XWF","executionInfo":{"status":"ok","timestamp":1646999933206,"user_tz":-420,"elapsed":22,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["def valid(model, valid_dataset):\n","    '''\n","    Performs validation.\n","    '''\n","    \n","    print(\"Starting validation .........\")\n","   \n","    valid_loss = 0.\n","\n","    batch_count = 0\n","    \n","    f1, em = 0., 0.\n","    \n","    # puts the model in eval mode. Turns off dropout\n","    model.eval()\n","    \n","    predictions = {}\n","    \n","    for batch in valid_dataset:\n","\n","        if batch_count % 500 == 0:\n","            print(f\"Starting batch {batch_count}\")\n","        batch_count += 1\n","\n","        context, question, context_mask, question_mask, label, context_text, answers, ids = batch\n","\n","        context, context_mask, question, question_mask, label = context.to(device), context_mask.to(device),\\\n","                                    question.to(device), question_mask.to(device), label.to(device)\n","\n","        with torch.no_grad():\n","\n","            preds = model(context, question, context_mask, question_mask)\n","\n","            p1, p2 = preds\n","\n","            y1, y2 = label[:,0], label[:,1]\n","\n","            loss = F.nll_loss(p1, y1) + F.nll_loss(p2, y2)\n","\n","            valid_loss += loss.item()\n","\n","            \n","            # get the start and end index positions from the model preds\n","            \n","            batch_size, c_len = p1.size()\n","            ls = nn.LogSoftmax(dim=1)\n","            mask = (torch.ones(c_len, c_len) * float('-inf')).to(device).tril(-1).unsqueeze(0).expand(batch_size, -1, -1)\n","            \n","            score = (ls(p1).unsqueeze(2) + ls(p2).unsqueeze(1)) + mask\n","            score, s_idx = score.max(dim=1)\n","            score, e_idx = score.max(dim=1)\n","            s_idx = torch.gather(s_idx, 1, e_idx.view(-1, 1)).squeeze()\n","            \n","            # stack predictions\n","            for i in range(batch_size):\n","                id = ids[i]\n","                pred = context[i][s_idx[i]:e_idx[i]+1]\n","                pred = ' '.join([idx2word[idx.item()] for idx in pred])\n","                predictions[id] = pred\n","            \n","            \n","            \n","    em, f1 = evaluate(predictions)            \n","    return valid_loss/len(valid_dataset), em, f1"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"705PMhOB3XZH","executionInfo":{"status":"ok","timestamp":1646999933208,"user_tz":-420,"elapsed":21,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["def evaluate(predictions):\n","    '''\n","    Gets a dictionary of predictions with question_id as key\n","    and prediction as value. The validation dataset has multiple \n","    answers for a single question. Hence we compare our prediction\n","    with all the answers and choose the one that gives us\n","    the maximum metric (em or f1). \n","    This method first parses the JSON file, gets all the answers\n","    for a given id and then passes the list of answers and the \n","    predictions to calculate em, f1.\n","    \n","    \n","    :param dict predictions\n","    Returns\n","    : exact_match: 1 if the prediction and ground truth  match exactly, 0 otherwise.\n","    : f1_score: \n","    '''\n","    f1 = exact_match = total = 0\n","    for ctx_id in  valid_df.id[valid_df.id.isin(predictions.keys())].unique():\n","      ground_truths = valid_df[valid_df.id == ctx_id][\"answer\"].to_list()\n","      prediction = predictions[ctx_id]\n","      exact_match += metric_max_over_ground_truths( exact_match_score, prediction, ground_truths)\n","      f1 += metric_max_over_ground_truths(f1_score, prediction, ground_truths)\n","      total += 1\n","    \n","    exact_match = 100.0 * exact_match / total\n","    f1 = 100.0 * f1 / total\n","    \n","    return exact_match, f1"]},{"cell_type":"code","source":["def normalize_answer(s):\n","    '''\n","    Performs a series of cleaning steps on the ground truth and \n","    predicted answer.\n","    '''\n","    def remove_articles(text):\n","        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))"],"metadata":{"id":"p263RUQLBxAQ","executionInfo":{"status":"ok","timestamp":1646999933209,"user_tz":-420,"elapsed":20,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n","    '''\n","    Returns maximum value of metrics for predicition by model against\n","    multiple ground truths.\n","    \n","    :param func metric_fn: can be 'exact_match_score' or 'f1_score'\n","    :param str prediction: predicted answer span by the model\n","    :param list ground_truths: list of ground truths against which\n","                               metrics are calculated. Maximum values of \n","                               metrics are chosen.\n","                            \n","    \n","    '''\n","    scores_for_ground_truths = []\n","    for ground_truth in ground_truths:\n","        score = metric_fn(prediction, ground_truth)\n","        scores_for_ground_truths.append(score)\n","        \n","    return max(scores_for_ground_truths)"],"metadata":{"id":"oEhaluSTBz8f","executionInfo":{"status":"ok","timestamp":1646999933210,"user_tz":-420,"elapsed":16,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["def f1_score(prediction, ground_truth):\n","    '''\n","    Returns f1 score of two strings.\n","    '''\n","    prediction_tokens = normalize_answer(prediction).split()\n","    ground_truth_tokens = normalize_answer(ground_truth).split()\n","    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n","    num_same = sum(common.values())\n","    if num_same == 0:\n","        return 0\n","    precision = 1.0 * num_same / len(prediction_tokens)\n","    recall = 1.0 * num_same / len(ground_truth_tokens)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1"],"metadata":{"id":"TAAY7KiAB2UA","executionInfo":{"status":"ok","timestamp":1646999933210,"user_tz":-420,"elapsed":15,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["def exact_match_score(prediction, ground_truth):\n","    '''\n","    Returns exact_match_score of two strings.\n","    '''\n","    return (normalize_answer(prediction) == normalize_answer(ground_truth))"],"metadata":{"id":"c_qwgDCRB6LF","executionInfo":{"status":"ok","timestamp":1646999933706,"user_tz":-420,"elapsed":509,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","execution_count":92,"metadata":{"id":"V7NQHgpE3XdI","executionInfo":{"status":"ok","timestamp":1646999933708,"user_tz":-420,"elapsed":10,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}}},"outputs":[],"source":["def epoch_time(start_time, end_time):\n","    '''\n","    Helper function to record epoch time.\n","    '''\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"markdown","metadata":{"id":"2t-WNmVI3kPo"},"source":["# Training Model"]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":141060,"status":"error","timestamp":1647000165482,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"},"user_tz":-420},"id":"5HN9Oe4P3m3j","outputId":"45fe366d-2393-45f6-f238-513254be8f3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","Starting training ........\n","Starting batch: 0\n","Starting batch: 50\n","Starting batch: 100\n","Starting batch: 150\n","Starting batch: 200\n","Starting batch: 250\n","Starting validation .........\n","Starting batch 0\n","Epoch train loss : nan| Time: 0m 55s\n","Epoch valid loss: nan\n","Epoch EM: 0.7722007722007722\n","Epoch F1: 2.1492921492921493\n","====================================================================================\n","Epoch 2\n","Starting training ........\n","Starting batch: 0\n","Starting batch: 50\n","Starting batch: 100\n","Starting batch: 150\n","Starting batch: 200\n","Starting batch: 250\n","Starting validation .........\n","Starting batch 0\n","Epoch train loss : nan| Time: 0m 56s\n","Epoch valid loss: nan\n","Epoch EM: 0.7722007722007722\n","Epoch F1: 2.1492921492921493\n","====================================================================================\n","Epoch 3\n","Starting training ........\n","Starting batch: 0\n","Starting batch: 50\n","Starting batch: 100\n","Starting batch: 150\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-93-4269aee46038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-85-ac59521063d7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# backward pass, calculates the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["start_tm = time.time()\n","\n","train_losses = []\n","valid_losses = []\n","ems = []\n","f1s = []\n","epochs = 3\n","\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch+1}\")\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_dataset)\n","    valid_loss, em, f1 = valid(model, valid_dataset)\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    ems.append(em)\n","    f1s.append(f1)\n","    \n","    print(f\"Epoch train loss : {train_loss}| Time: {epoch_mins}m {epoch_secs}s\")\n","    print(f\"Epoch valid loss: {valid_loss}\")\n","    print(f\"Epoch EM: {em}\")\n","    print(f\"Epoch F1: {f1}\")\n","    print(\"====================================================================================\")\n","\n","print(f\"Total Runingtime {time.time() - start_tm}\")"]},{"cell_type":"markdown","metadata":{"id":"h8bKj26w7P3y"},"source":["# Check Training"]},{"cell_type":"code","source":["class New_DocumentReader(nn.Module):\n","    \n","    def __init__(self, hidden_dim, embedding_dim, num_layers, num_directions, dropout, device):\n","        \n","        super().__init__()\n","        \n","        self.device = device\n","        \n","        #self.embedding = self.get_glove_embedding()\n","        \n","        self.context_bilstm = StackedBiLSTM(embedding_dim * 2, hidden_dim, num_layers, dropout)\n","        \n","        self.question_bilstm = StackedBiLSTM(embedding_dim, hidden_dim, num_layers, dropout)\n","        \n","        self.glove_embedding = self.get_glove_embedding()\n","        \n","        def tune_embedding(grad, words=61036):\n","            grad[words:] = 0\n","            return grad\n","        \n","        #self.glove_embedding.weight.register_hook(tune_embedding)\n","        \n","        self.align_embedding = AlignQuestionEmbedding(embedding_dim)\n","        \n","        self.linear_attn_question = LinearAttentionLayer(hidden_dim*num_layers*num_directions) \n","        \n","        self.bilinear_attn_start = BilinearAttentionLayer(hidden_dim*num_layers*num_directions, \n","                                                          hidden_dim*num_layers*num_directions)\n","        \n","        self.bilinear_attn_end = BilinearAttentionLayer(hidden_dim*num_layers*num_directions,\n","                                                        hidden_dim*num_layers*num_directions)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","   \n","        \n","    def get_glove_embedding(self):\n","        \n","        weights_matrix = np.load('./drqa/1-tokenizers/result/dfqa2v_ltw2v.npy')\n","        num_embeddings, embedding_dim = weights_matrix.shape\n","        embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights_matrix).to(self.device),freeze=False ,padding_idx=0)\n","\n","        return embedding\n","    \n","    \n","    def forward(self, context, question, context_mask, question_mask):\n","       \n","        # context = [bs, len_c]\n","        # question = [bs, len_q]\n","        # context_mask = [bs, len_c]\n","        # question_mask = [bs, len_q]\n","        \n","        \n","        ctx_embed = self.glove_embedding(context)\n","        # ctx_embed = [bs, len_c, emb_dim]\n","        \n","        ques_embed = self.glove_embedding(question)\n","        # ques_embed = [bs, len_q, emb_dim]\n","        \n","\n","        ctx_embed = self.dropout(ctx_embed)\n","     \n","        ques_embed = self.dropout(ques_embed)\n","             \n","        align_embed = self.align_embedding(ctx_embed, ques_embed, question_mask)\n","        # align_embed = [bs, len_c, emb_dim]  \n","        \n","        ctx_bilstm_input = torch.cat([ctx_embed, align_embed], dim=2)\n","        # ctx_bilstm_input = [bs, len_c, emb_dim*2]\n","                \n","        ctx_outputs = self.context_bilstm(ctx_bilstm_input)\n","        # ctx_outputs = [bs, len_c, hid_dim*layers*dir] = [bs, len_c, hid_dim*6]\n","       \n","        qtn_outputs = self.question_bilstm(ques_embed)\n","        # qtn_outputs = [bs, len_q, hid_dim*6]\n","    \n","        qtn_weights = self.linear_attn_question(qtn_outputs, question_mask)\n","        # qtn_weights = [bs, len_q]\n","            \n","        qtn_weighted = weighted_average(qtn_outputs, qtn_weights)\n","        # qtn_weighted = [bs, hid_dim*6]\n","        \n","        start_scores = self.bilinear_attn_start(ctx_outputs, qtn_weighted, context_mask)\n","        # start_scores = [bs, len_c]\n","         \n","        end_scores = self.bilinear_attn_end(ctx_outputs, qtn_weighted, context_mask)\n","        # end_scores = [bs, len_c]\n","        \n","      \n","        return start_scores, end_scores\n","        #, qtn_weighted, qtn_weights, qtn_outputs, ctx_outputs, ctx_outputs, ctx_bilstm_input, align_embed, ques_embed, ques_embed, ctx_embed"],"metadata":{"id":"b09CjucxXZ8l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda')\n","EMB_DIM = 300\n","HIDDEN_DIM = 128\n","NUM_LAYERS = 1\n","NUM_DIRECTIONS = 2\n","DROPOUT = 0.3\n","device = torch.device('cuda')\n","\n","model = New_DocumentReader(HIDDEN_DIM, EMB_DIM,  NUM_LAYERS,  NUM_DIRECTIONS,  DROPOUT,  device).to(device)\n","optimizer = torch.optim.Adamax(model.parameters())\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wnmiAT7YXfyd","executionInfo":{"status":"ok","timestamp":1645918553006,"user_tz":-420,"elapsed":3,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"04a30f61-b9da-43dd-dde6-db7a900402e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 19,720,781 trainable parameters\n"]}]},{"cell_type":"code","source":["def loopBatch(dataset,loop_n):\n","  for i,batch in enumerate(dataset):\n","    if i >loop_n:\n","      break\n","    else :\n","      context, question, context_mask, question_mask, label, context_text, answers, ids  = batch\n","  return context, question, context_mask, question_mask, label, context_text, answers, ids"],"metadata":{"id":"jCoPgUBNDBFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda')\n","# place the tensors on GPU\n","context, question, context_mask, question_mask, label, context_text, answers, ids = loopBatch(train_dataset,3)\n","context, context_mask, question, question_mask, label = context.to(device), context_mask.to(device), question.to(device), question_mask.to(device), label.to(device)"],"metadata":{"id":"5caA3bhBDKVv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset.batch_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39rwZUIMZf9e","executionInfo":{"status":"ok","timestamp":1645918697080,"user_tz":-420,"elapsed":7,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"185e5627-813b-455a-c94c-bc854aed3577"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32"]},"metadata":{},"execution_count":175}]},{"cell_type":"code","source":["for i in range(0,20):\n","  context, question, context_mask, question_mask, label, context_text, answers, ids = loopBatch(train_dataset,3)\n","  context, context_mask, question, question_mask, label = context.to(device), context_mask.to(device), question.to(device), question_mask.to(device), label.to(device)\n","  preds = model(context, question, context_mask, question_mask)\n","  print(f\"Batch {i} : loss : {F.cross_entropy(preds[0], label[:,0]) + F.cross_entropy(preds[1], label[:,1])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QlPLPzK3YDbc","executionInfo":{"status":"ok","timestamp":1645918820319,"user_tz":-420,"elapsed":16699,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"7f8d318a-0eb3-410c-f418-9d0681f4fb52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0 : loss : 11.424909591674805\n","Batch 1 : loss : 11.35029411315918\n","Batch 2 : loss : 11.533506393432617\n","Batch 3 : loss : 11.459067344665527\n","Batch 4 : loss : 11.364566802978516\n","Batch 5 : loss : 11.543905258178711\n","Batch 6 : loss : 11.60793399810791\n","Batch 7 : loss : 11.500799179077148\n","Batch 8 : loss : 11.467121124267578\n","Batch 9 : loss : 11.52192497253418\n","Batch 10 : loss : 11.595657348632812\n","Batch 11 : loss : 11.583470344543457\n","Batch 12 : loss : 11.617942810058594\n","Batch 13 : loss : 11.575180053710938\n","Batch 14 : loss : 11.454253196716309\n","Batch 15 : loss : 11.449477195739746\n","Batch 16 : loss : 11.552932739257812\n","Batch 17 : loss : 11.547327041625977\n","Batch 18 : loss : 11.537164688110352\n","Batch 19 : loss : 11.581380844116211\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hbD-thuQ7e9f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645918561812,"user_tz":-420,"elapsed":525,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"ff6e3778-04e0-4f9e-9e2b-f5ef4801cd2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([[ 0.2457,  0.1388, -0.0681,  ...,    -inf,    -inf,    -inf],\n","        [ 0.4133,  0.4432,  0.8993,  ...,    -inf,    -inf,    -inf],\n","        [ 0.5402,  0.2073, -0.1529,  ...,    -inf,    -inf,    -inf],\n","        ...,\n","        [ 0.2609,  0.4207, -0.2915,  ...,    -inf,    -inf,    -inf],\n","        [-0.1516, -0.5904, -0.5457,  ...,    -inf,    -inf,    -inf],\n","        [ 0.5432,  0.1943,  0.2013,  ...,    -inf,    -inf,    -inf]],\n","       device='cuda:0', grad_fn=<MaskedFillBackward0>), tensor([[-0.0410, -0.2035,  0.1451,  ...,    -inf,    -inf,    -inf],\n","        [ 0.7891,  0.3434,  0.3288,  ...,    -inf,    -inf,    -inf],\n","        [-0.2050, -0.2274, -0.6105,  ...,    -inf,    -inf,    -inf],\n","        ...,\n","        [-0.6340, -1.2802, -0.1492,  ...,    -inf,    -inf,    -inf],\n","        [-0.2392,  0.2916, -0.4470,  ...,    -inf,    -inf,    -inf],\n","        [ 0.5709, -0.0878,  0.0837,  ...,    -inf,    -inf,    -inf]],\n","       device='cuda:0', grad_fn=<MaskedFillBackward0>))\n","tensor(11.4667, device='cuda:0', grad_fn=<AddBackward0>)\n"]}],"source":["# forward pass, get the predictions\n","preds = model(context, question, context_mask, question_mask)\n","start_pred, end_pred = preds\n","print(preds)\n","        \n","# separate labels for start and end position\n","start_label, end_label = label[:,0], label[:,1]\n","        \n","# calculate loss\n","loss = F.cross_entropy(start_pred, start_label) + F.cross_entropy(end_pred, end_label)\n","print(loss)"]},{"cell_type":"code","source":["def tune_embedding(grad, words=1000):\n","    grad[words:] = 0\n","    return grad"],"metadata":{"id":"e-6eat6_N8cr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights_matrix).to(device),freeze=False ,padding_idx=0)\n","embedding.weight.register_hook(tune_embedding)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W9Qn27PREjFv","executionInfo":{"status":"ok","timestamp":1645917861811,"user_tz":-420,"elapsed":420,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"547a6b8b-8c4e-48ab-d939-645466a2e06a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.utils.hooks.RemovableHandle at 0x7fcc30b0af50>"]},"metadata":{},"execution_count":136}]},{"cell_type":"code","source":["ctx_embed = embedding(context).to(device)\n","ques_embed = embedding(question).to(device)\n","dropout = nn.Dropout(0.3)\n","ctx_embed = dropout(ctx_embed).to(device)\n","ques_embed = dropout(ques_embed).to(device)\n","print(f\"Size of ctx_embed {ctx_embed.size()}\")\n","print(f\"Size of ques_embed {ques_embed.size()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fV39NZyiFLnX","executionInfo":{"status":"ok","timestamp":1645917865210,"user_tz":-420,"elapsed":2,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"02057f31-2ca5-41e2-bf6c-4e7eda14b35d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of ctx_embed torch.Size([32, 774, 300])\n","Size of ques_embed torch.Size([32, 30, 300])\n"]}]},{"cell_type":"code","source":["align_embedding = AlignQuestionEmbedding(300).to(device)\n","align_embed = align_embedding(ctx_embed, ques_embed, question_mask)"],"metadata":{"id":"VFa0CIXrE3Z1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ctx_bilstm_input = torch.cat([ctx_embed, align_embed], dim=2)"],"metadata":{"id":"YZwTPBXYLIqG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["context_bilstm = StackedBiLSTM(300 * 2, 128, 1, 0.3).to(device)\n","ctx_outputs = context_bilstm(ctx_bilstm_input)"],"metadata":{"id":"NqJN0y06LWpW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question_bilstm = StackedBiLSTM(300, 128, 1, 0.3).to(device)\n","qtn_outputs = question_bilstm(ques_embed)\n","print(f\"Size of qtn_outputs {qtn_outputs.size()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVPGFgsuL1QC","executionInfo":{"status":"ok","timestamp":1645916855525,"user_tz":-420,"elapsed":9,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"dd669ed5-f92d-461c-c26d-1230100240cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of qtn_outputs torch.Size([32, 30, 256])\n"]}]},{"cell_type":"code","source":["linear_attn_question = LinearAttentionLayer(128*1*2) .to(device)\n","qtn_weights = linear_attn_question(qtn_outputs, question_mask)\n","print(f\"Size of qtn_weights {qtn_weights.size()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N8Pe9DBjMRCx","executionInfo":{"status":"ok","timestamp":1645916856638,"user_tz":-420,"elapsed":7,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"5b77f16d-e639-46a6-8541-09b165508b2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of qtn_weights torch.Size([32, 30])\n"]}]},{"cell_type":"code","source":["qtn_weighted = weighted_average(qtn_outputs, qtn_weights)\n","print(f\"Size of qtn_weighted {qtn_weighted.size()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kGOftGkfMeCc","executionInfo":{"status":"ok","timestamp":1645916858206,"user_tz":-420,"elapsed":9,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"d43bfe65-d651-45ba-c00e-9dd573f3260a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of qtn_weighted torch.Size([32, 256])\n"]}]},{"cell_type":"code","source":["bilinear_attn_start = BilinearAttentionLayer(128*1*2, 128*1*2).to(device)\n","start_scores = bilinear_attn_start(ctx_outputs, qtn_weighted, context_mask)"],"metadata":{"id":"SENXTB6QM2TW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bilinear_attn_end = BilinearAttentionLayer(128*1*2, 128*1*2).to(device)\n","end_scores = bilinear_attn_end(ctx_outputs, qtn_weighted, context_mask)"],"metadata":{"id":"Z347sI65NcDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["F.cross_entropy(start_scores, start_label) + F.cross_entropy(end_scores, end_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pK5TmmvpNqig","executionInfo":{"status":"ok","timestamp":1645916863295,"user_tz":-420,"elapsed":10,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"e4908de8-36b3-49ea-e86e-a1b1a958410f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(11.7582, device='cuda:0', grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":125}]},{"cell_type":"code","source":["start_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-JxFgXLSqfl","executionInfo":{"status":"ok","timestamp":1645916893646,"user_tz":-420,"elapsed":5,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"a8ed9312-dd3c-4cca-f390-2c7d01f40394"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.3630, -0.2777, -0.1493,  ...,    -inf,    -inf,    -inf],\n","        [-0.2866, -0.0476, -0.4334,  ...,    -inf,    -inf,    -inf],\n","        [ 0.0096, -0.0054,  0.1559,  ...,    -inf,    -inf,    -inf],\n","        ...,\n","        [ 0.6172,  0.6508,  0.3309,  ...,    -inf,    -inf,    -inf],\n","        [-0.6726, -0.2234,  0.0203,  ...,    -inf,    -inf,    -inf],\n","        [-0.8651, -0.4073, -0.6602,  ...,    -inf,    -inf,    -inf]],\n","       device='cuda:0', grad_fn=<MaskedFillBackward0>)"]},"metadata":{},"execution_count":127}]},{"cell_type":"code","source":["start_label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SH9CxeTfSob6","executionInfo":{"status":"ok","timestamp":1645916885351,"user_tz":-420,"elapsed":9,"user":{"displayName":"taitip Suphasiriwattana","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16893195790372778185"}},"outputId":"f5dae3a8-a3c3-4f5f-e4c6-ec6583f7e1ea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([133, 272,  24,   0,  96,  33,  27,  18,  11,  35, 329, 303, 187,  13,\n","         47, 159,  33,  58, 145,  15,   0, 112,  99,  42,  93,  64,  18,  15,\n","        342,  18,   0,  33], device='cuda:0')"]},"metadata":{},"execution_count":126}]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":["qUSjaq2C0Xdl","9-Ov1HJ10cSr","v15bqdFi0x60","0YqC6MDCpm_U","MCE3wZTMBXwm","z_Ui7-6r3Lzy","EaD2ccj13Reb"],"machine_shape":"hm","name":"model_reader.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOAf8pX4NGtAI5qxrqhqjsx"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}